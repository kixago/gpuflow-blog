---
title: "10달러 이하로 Stable Diffusion LoRA 모델 훈련하는 방법"
description: "임대 GPU를 사용하여 Stable Diffusion용 커스텀 LoRA 모델을 훈련하는 단계별 가이드. GPU 선택, 데이터셋 준비, 훈련 구성 및 비용 최적화를 다루는 완전한 튜토리얼."
excerpt: "GPU 임대를 사용하여 고품질 LoRA 모델을 훈련하는 실용적인 튜토리얼. 프로바이더 선택, 구성 및 총 비용을 10달러 이하로 유지하는 기술을 다룹니다."
pubDate: 2026-02-11
updatedDate: 2026-02-11
locale: "ko"
category: "tutorials"
featured: false
draft: false
author: "GPUFlow 팀"
heroImage: "../_images/stable-diffusion-lora-training-guide.jpg"
heroImageAlt: "냉각 팬과 LED 조명이 보이는 서버 랙에 설치된 NVIDIA 그래픽 카드"
faq:
  - question: "임대 대신 자체 GPU를 사용하여 LoRA 모델을 훈련할 수 있나요?"
    answer: "예, RTX 3060 이상과 같이 최소 12GB VRAM을 가진 NVIDIA GPU가 있다면 가능합니다. 그러나 전기 비용, 하드웨어 마모 및 소비자 하드웨어에서 훨씬 긴 훈련 시간은 종종 가끔씩 하는 프로젝트에는 임대가 더 경제적인 선택이 되게 합니다."
  - question: "일반적인 LoRA 훈련 세션은 얼마나 걸리나요?"
    answer: "RTX 4090 또는 RTX 3090을 사용할 때 대부분의 LoRA 훈련 세션은 1~3시간 내에 완료됩니다. 정확한 기간은 데이터셋 크기, 훈련 에포크 수 및 배치 크기 구성에 따라 달라집니다."
  - question: "LoRA 훈련에 필요한 최소 이미지 수는 얼마인가요?"
    answer: "15~20개의 이미지만으로도 합리적인 결과를 얻을 수 있습니다. 그러나 30~100개의 잘 캡션된 이미지를 포함하는 데이터셋이 일반적으로 더 나은 품질을 제공합니다. 이미지 품질과 캡션 정확도가 원시 수량보다 더 중요합니다."
  - question: "어느 GPU 임대 제공업체가 LoRA 훈련에 가장 좋은 가치를 제공하나요?"
    answer: "Vast.ai는 일반적으로 RTX 4090 GPU에 대해 가장 낮은 시간당 요금을 제공합니다. GPUFlow는 암호화폐 결제 옵션과 신원 확인 요구 사항 없이 경쟁력 있는 가격을 제공합니다. RunPod는 GPU 임대 초보자에게 가장 간단한 인터페이스를 제공합니다."
  - question: "단일 세션에서 여러 LoRA 모델을 훈련하는 것이 더 비용 효율적인가요?"
    answer: "예. 하나의 연장된 세션에서 여러 LoRA를 일괄 훈련하면 반복되는 설정 시간을 제거하고 유휴 GPU 요금을 최소화합니다. 4시간 세션에서 3~5개의 LoRA 모델을 훈련하는 것은 일반적으로 개별적으로 훈련하는 데 드는 비용의 절반 미만입니다."
---

# 10달러 이하로 Stable Diffusion LoRA 모델 훈련하는 방법

Stable Diffusion용 커스텀 LoRA 모델 훈련은 개인화된 AI 생성 이미지를 만드는 가장 접근하기 쉬운 방법 중 하나가 되었습니다. 특정 예술 스타일을 재현하거나, 일관된 캐릭터 얼굴을 생성하거나, 제품 사진에 맞춰 모델을 미세 조정하고 싶든, LoRA 훈련을 통해 전체 모델 미세 조정의 계산 비용 없이 이러한 목표를 달성할 수 있습니다.

일반적인 가정은 이 과정에 비싼 로컬 하드웨어나 상당한 클라우드 컴퓨팅 예산이 필요하다는 것입니다. 둘 다 사실이 아닙니다. 현재의 GPU 임대 가격과 효율적인 훈련 구성을 사용하면 10달러 미만으로 프로덕션 품질의 LoRA 모델을 훈련할 수 있습니다—종종 훨씬 적은 비용으로.

이 가이드는 전체 프로세스를 안내합니다: 적절한 하드웨어 선택, 훈련 데이터셋 준비, 훈련 매개변수 구성, 훈련 실행 및 결과 검증. 실제 프로젝트 예산을 계획하는 사람에게 "저렴한 AI 훈련"이라는 모호한 약속은 도움이 되지 않기 때문에 각 단계에서 비용에 대해 구체적으로 설명하겠습니다.

**시작하기 전에 필요한 것:**

- 20~100개의 훈련 이미지 (아래 선택 기준에 대한 자세한 내용)
- 명령줄 인터페이스에 대한 기본적인 친숙함
- GPU 임대 결제를 위한 암호화폐 지갑 또는 신용카드
- 약 2~4시간의 집중 시간
- 첫 번째 훈련 실행을 위한 5~15달러의 예산

![머신 러닝 워크로드에 사용되는 고성능 GPU 서버가 줄지어 있는 현대적인 데이터 센터 내부](../_images/data-center-with-person.jpg)

---

## 목차

- [LoRA 이해 및 중요한 이유](#lora-이해-및-중요한-이유)
- [훈련을 위한 올바른 GPU 선택](#훈련을-위한-올바른-gpu-선택)
- [GPU 임대 제공업체 비교](#gpu-임대-제공업체-비교)
- [훈련 데이터셋 준비](#훈련-데이터셋-준비)
- [훈련 환경 설정](#훈련-환경-설정)
- [훈련 매개변수 구성](#훈련-매개변수-구성)
- [훈련 실행](#훈련-실행)
- [LoRA 검증 및 테스트](#lora-검증-및-테스트)
- [비용 최적화 전략](#비용-최적화-전략)
- [일반적인 문제 및 해결방법](#일반적인-문제-및-해결방법)
- [자주 묻는 질문](#자주-묻는-질문)

---

## LoRA 이해 및 중요한 이유

LoRA는 Low-Rank Adaptation의 약자로, 전체 모델을 수정하는 대신 소수의 추가 매개변수를 훈련하여 대규모 신경망을 미세 조정하는 기술입니다. 원래 Stable Diffusion 모델에는 거의 10억 개의 매개변수가 포함되어 있습니다. 전체 미세 조정은 이들 모두를 수정해야 하며, 상당한 GPU 메모리와 긴 훈련 시간이 필요합니다.

LoRA는 원래 모델 가중치를 동결하고 모델이 정보를 처리하는 방식을 수정하는 작은 어댑터 매트릭스를 훈련함으로써 이 문제를 우회합니다. 일반적인 LoRA 파일은 10~200메가바이트 크기인 반면, 전체 Stable Diffusion 체크포인트는 2~6기가바이트입니다.

실질적인 영향은 상당합니다:

**메모리 효율성.** LoRA 훈련은 전체 미세 조정보다 훨씬 적은 GPU VRAM을 필요로 합니다. 24GB GPU는 전체 미세 조정에 40GB 이상이 필요한 SDXL 모델용 LoRA를 편안하게 훈련할 수 있습니다.

**훈련 속도.** 더 적은 매개변수를 훈련하기 때문에 각 훈련 에포크가 더 빨리 완료됩니다. 전체 미세 조정에 12시간이 걸릴 수 있는 작업을 LoRA로는 90분 안에 완료할 수 있습니다.

**조합 가능성.** 여러 LoRA를 추론 시점에 결합할 수 있습니다. 예술 스타일을 위한 하나의 LoRA와 캐릭터 일관성을 위한 다른 LoRA를 사용하여 재훈련 없이 다양한 강도로 혼합할 수 있습니다.

**저장 및 배포.** 작은 파일 크기로 LoRA를 공유하고 유지 관리하기가 실용적입니다. 저장 문제 없이 수십 개의 전문화된 LoRA를 합리적으로 보관할 수 있습니다.

이러한 효율성으로 인한 비용 절감이 10달러 미만의 훈련을 가능하게 합니다. 8~24시간이 아닌 1~3시간 동안 비싼 하드웨어를 임대하는 것입니다.

---

## 훈련을 위한 올바른 GPU 선택

GPU 선택에는 세 가지 요소의 균형이 포함됩니다: VRAM 용량, 훈련 속도 및 임대 비용. 최소 가능 옵션과 최적의 선택은 크게 다릅니다.

### VRAM 요구 사항

Stable Diffusion 1.5 LoRA 훈련의 경우 12GB VRAM이 실질적인 최소값입니다. 배치 크기와 해상도를 줄여 8GB로 작동시킬 수 있지만 훈련 품질이 종종 저하됩니다.

SDXL LoRA 훈련의 경우 16GB가 최소이며 24GB가 강력히 권장됩니다. SDXL 모델은 더 크고 요구 사항이 더 높습니다. 불충분한 VRAM으로 SDXL 훈련을 시도하면 지속적인 메모리 스와핑이 발생하여 프로세스가 크게 느려지고 종종 훈련 실패로 이어집니다.

### 속도와 비용의 트레이드오프

더 비싼 GPU는 더 빨리 훈련하지만 시간당 비용 증가가 항상 전체 프로젝트 비용을 비례적으로 줄이는 것은 아닙니다. 일반적인 SD 1.5 LoRA 훈련을 위한 비교를 고려하십시오:

| GPU         | VRAM | 대략적인 훈련 시간 | 일반적인 시간당 요금 | 예상 총 비용 |
| ----------- | ---- | ------------------ | -------------------- | ------------ |
| RTX 3090    | 24GB | 2.5시간            | $0.50                | $1.25        |
| RTX 4090    | 24GB | 1.5시간            | $0.70                | $1.05        |
| RTX A6000   | 48GB | 1.5시간            | $0.80                | $1.20        |
| A100 (40GB) | 40GB | 1.0시간            | $1.50                | $1.50        |

RTX 4090는 일반적으로 최고의 비용 효율성을 제공합니다. 데이터센터 GPU만큼 빠르게 훈련하면서 시간당 요금은 훨씬 낮습니다. RTX 3090은 4090 가용성이 제한적일 때 여전히 실행 가능하며 전체 비용은 약간만 더 높습니다.

SDXL LoRA 훈련의 경우, 더 큰 모델이 추가 VRAM과 메모리 대역폭으로부터 더 많은 이점을 얻기 때문에 계산이 약간 달라집니다. A100은 소비자 하드웨어에서 4시간 이상 걸릴 수 있는 복잡한 SDXL 프로젝트에 더 경쟁력이 있습니다.

기업용 클라우드 옵션 및 마켓플레이스 플랫폼을 포함한 모든 주요 제공업체의 GPU 임대 가격에 대한 포괄적인 분석은 [2026년 GPU 임대 가격 완전 비교](/ko/gpu-rental-pricing-comparison-2026/)를 참조하십시오.

![AI 모델 훈련에 일반적으로 사용되는 3중 팬 냉각 시스템을 갖춘 NVIDIA RTX 4090 그래픽 카드](../_images/nvidia-4090.jpg)

---

## GPU 임대 제공업체 비교

LoRA 훈련 워크로드를 위해 고려할 가치가 있는 세 가지 제공업체가 있습니다. 각각은 결제 선호도, 기술적 편안함 수준 및 비용 민감도에 따라 중요한 고유한 특성을 가지고 있습니다.

### Vast.ai

Vast.ai는 개별 GPU 소유자가 하드웨어를 임대하는 P2P 마켓플레이스를 운영합니다. 이 모델은 시장에서 가장 낮은 가격을 생성하며, RTX 4090 GPU는 시간당 $0.35~$0.60에 자주 이용할 수 있습니다.

트레이드오프는 가변성과 관련이 있습니다. 제공업체 신뢰성은 개별 호스트에 따라 97%에서 99.9%까지 다양합니다. 수요에 따라 가용성이 변동합니다. 데이터셋 업로드를 위해 허용 가능한 네트워크 속도를 가진 제공업체를 찾기 전에 여러 제공업체를 시도해야 할 수 있습니다.

제공업체 메트릭을 평가하는 데 익숙한 숙련된 사용자의 경우 Vast.ai는 가능한 최저 훈련 비용을 제공합니다. 초기 설정 및 제공업체 평가를 위해 30분을 추가로 예산에 포함하십시오.

### RunPod

RunPod는 순수 마켓플레이스와 기업 클라우드 제공업체 사이에 위치합니다. 플랫폼은 커뮤니티 소스 GPU와 더 일관된 성능을 제공하는 전용 "Secure Cloud" 인스턴스를 모두 제공합니다.

가격은 Vast.ai보다 약간 높으며, Secure Cloud 티어의 RTX 4090 액세스는 일반적으로 시간당 $0.59입니다. 플랫폼은 더 쉬운 설정, 일반적인 AI 워크로드를 위한 사전 구성된 템플릿 및 더 예측 가능한 가용성으로 이를 보완합니다.

GPU 임대 초보자이거나 최소 비용 최적화보다 간단한 인터페이스를 중요하게 생각하는 사용자에게 RunPod는 합리적인 중간 지점을 나타냅니다.

### GPUFlow

GPUFlow는 결제 처리를 위해 스마트 계약 에스크로를 사용하는 블록체인 인프라에 구축된 P2P 마켓플레이스를 운영합니다. 플랫폼은 암호화폐 결제를 수락하며 신원 확인이 필요하지 않습니다.

가격은 일반적으로 Vast.ai와 RunPod 사이에 있으며, RTX 4090 액세스는 시간당 $0.50~$0.80입니다. 구별되는 특징은 결제 개인 정보 보호, 즉시 설정(일반적으로 실행 인스턴스까지 30초 미만) 및 경쟁 마켓플레이스보다 낮은 플랫폼 수수료입니다.

암호화폐 결제를 선호하거나, 거래 개인 정보 보호를 중요하게 생각하거나, 전통적인 제공업체에서 흔한 계정 확인 프로세스를 피하고 싶은 사용자에게 GPUFlow는 간소화된 대안을 제공합니다.

### 제공업체 요약

| 제공업체 | RTX 4090 가격 범위        | 설정 시간 | 결제 옵션          | 최적의 용도          |
| -------- | ------------------------- | --------- | ------------------ | -------------------- |
| Vast.ai  | $0.35-0.60/시간           | 5-15분    | 신용카드           | 최대 비용 절감       |
| RunPod   | $0.59/시간 (Secure Cloud) | 2-5분     | 신용카드, 암호화폐 | 사용 편의성          |
| GPUFlow  | $0.50-0.80/시간           | 30초      | 암호화폐만         | 개인 정보 보호, 속도 |

## 훈련 데이터셋 준비

데이터셋 품질은 다른 어떤 요소보다 훈련 결과를 더 많이 결정합니다. 신중하게 선별된 30개 이미지 세트는 부주의하게 조립된 200개 이미지 컬렉션보다 더 나은 결과를 생성합니다.

### 이미지 선택 기준

**일관성.** 모든 이미지는 모델이 학습하기를 원하는 개념을 나타내야 합니다. 특정 사람의 얼굴을 훈련하는 경우 모든 이미지는 그 얼굴을 명확하게 보여야 합니다. 예술 스타일을 훈련하는 경우 모든 이미지는 해당 스타일을 예시해야 합니다.

**일관성 내의 다양성.** 개념적 일관성을 유지하면서 기술적 측면을 다양화하십시오. 다양한 각도, 조명 조건, 배경 및 맥락을 포함하십시오. 이러한 다양성은 모델이 특정 구성에 과적합되지 않고 일반화하는 방법을 가르칩니다.

**기술적 품질.** 선명하고 노출이 잘 된 이미지를 사용하십시오. 모션 블러, 노이즈, 압축 아티팩트 및 나쁜 조명은 모두 모델이 학습하는 내용의 일부가 됩니다. 훈련 이미지가 거칠다면 생성된 이미지도 거칠어지는 경향이 있습니다.

**해상도.** 훈련 이미지는 SD 1.5의 경우 최소 512x512 픽셀, SDXL의 경우 최소 1024x1024 픽셀이어야 합니다. 더 높은 해상도의 소스 이미지는 훈련 파이프라인이 품질 손실 없이 자르고 크기를 조정할 수 있게 합니다.

### 데이터셋 크기 가이드라인

최적의 데이터셋 크기는 개념 복잡성에 따라 달라집니다:

**단순한 개념 (단일 얼굴, 기본 스타일):** 20-40개 이미지
**중간 개념 (여러 의상을 입은 캐릭터, 미묘한 스타일):** 40-80개 이미지
**복잡한 개념 (상세한 환경, 매우 다양한 스타일):** 80-150개 이미지

더 많은 이미지는 더 많은 훈련 단계가 필요하여 시간과 비용이 증가합니다. 첫 번째 시도에서는 이러한 범위의 작은 쪽에서 시작하십시오.

### 이미지 캡션 작성

각 훈련 이미지에는 내용을 설명하는 텍스트 캡션이 필요합니다. 이러한 캡션은 모델에게 어떤 텍스트 개념을 시각적 패턴과 연관시킬지 가르칩니다.

효과적인 캡션은 구체적이고 일관적입니다:

**나쁜 캡션:** "여자"
**더 나은 캡션:** "짧은 갈색 머리와 녹색 눈을 가진 여성 Sarah Miller의 사진, 파란색 스웨터를 입고 있음"

**나쁜 캡션:** "판타지 아트"
**더 나은 캡션:** "빛나는 판타지 스타일의 디지털 페인팅, 어두운 숲에서 빛나는 버섯을 특징으로 함, 세밀한 선 작업, 생생한 보라색과 파란색 색상 팔레트"

추론 중에 사용하려는 트리거 단어 또는 구문은 모든 캡션에 나타나야 합니다. "빛나는 판타지 스타일로"로 LoRA를 호출하려면 해당 정확한 구문이 각 훈련 캡션에 나타나야 합니다.

작은 데이터셋의 경우 캡션 작성은 수동으로 수행할 수 있습니다. 더 큰 컬렉션의 경우 BLIP 또는 WD14 Tagger와 같은 도구가 초기 캡션을 생성할 수 있으며, 그런 다음 검토하고 다듬을 수 있습니다.

![LoRA 훈련을 위한 훈련 이미지와 해당 캡션 텍스트 파일을 보여주는 정리된 폴더 구조](../_images/file-folder-organization.png)

### 디렉토리 구조

훈련 스크립트가 예상하는 특정 구조로 훈련 데이터를 구성하십시오:

```
training_data/
├── 10_concept_name/
│   ├── image001.jpg
│   ├── image001.txt
│   ├── image002.jpg
│   ├── image002.txt
│   └── ...
```

폴더 이름 접두사(이 예에서 "10")는 해당 폴더의 각 이미지가 훈련 중에 몇 번 반복되어야 하는지를 나타냅니다. 숫자가 높을수록 훈련 과정에서 해당 이미지의 가중치가 증가합니다.

숫자 뒤의 밑줄로 구분된 이름은 커스텀 캡션을 사용하지 않는 경우 기본 트리거 단어가 됩니다.

---

## 훈련 환경 설정

데이터셋이 준비되고 GPU 임대가 확보되면 다음 단계는 훈련 환경을 구성하는 것입니다. LoRA 훈련을 위한 표준 도구 체인은 커뮤니티에서 유지 관리하는 오픈 소스 훈련 스크립트 모음인 kohya_ss/sd-scripts입니다.

### 초기 환경 설정

임대한 GPU 인스턴스에 연결한 후 훈련 저장소를 복제하고 종속성을 설치해야 합니다. 다음 명령은 기본 환경을 설정합니다:

```bash
# 훈련 스크립트 저장소 복제
git clone https://github.com/kohya-ss/sd-scripts.git
cd sd-scripts

# 가상 환경 생성 및 활성화
python -m venv venv
source venv/bin/activate

# 종속성 설치
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
pip install xformers
```

이 설치는 네트워크 속도에 따라 일반적으로 5~10분이 걸립니다. xformers 패키지는 선택 사항이지만 훈련 중 메모리 사용량을 크게 줄이므로 권장됩니다.

### 기본 모델 다운로드

LoRA 훈련에는 훈련할 기본 Stable Diffusion 모델이 필요합니다. 이를 인스턴스에 다운로드해야 합니다:

```bash
# 모델 디렉토리 생성
mkdir -p models/sd

# Stable Diffusion 1.5 다운로드 (약 4GB)
wget -O models/sd/v1-5-pruned.safetensors \
  "https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned.safetensors"
```

SDXL 훈련의 경우 약 6.5GB인 SDXL 기본 모델로 대체하십시오.

### 훈련 데이터 업로드

준비된 데이터셋을 GPU 인스턴스로 전송합니다. 대부분의 제공업체는 SCP 또는 SFTP를 지원합니다:

```bash
# 로컬 머신에서
scp -r ./training_data user@gpu-instance-ip:~/sd-scripts/
```

또는 데이터셋이 클라우드 스토리지에 저장된 경우 wget 또는 rclone을 사용하여 인스턴스에 직접 다운로드할 수 있습니다.

### GPUFlow 전용 설정

GPUFlow를 사용하는 경우 플랫폼은 대부분의 수동 설정을 제거하는 사전 구성된 환경을 제공합니다. 웹 기반 터미널을 통해 연결한 후:

```bash
# GPUFlow 인스턴스에는 사전 설치된 훈련 환경이 포함되어 있습니다
cd /workspace/sd-scripts

# 웹 인터페이스 또는 SCP를 사용하여 데이터셋 업로드
# 훈련 스크립트는 사전 구성되어 사용 준비가 되어 있습니다
```

이 사전 구성은 처음부터 베어 인스턴스를 설정하는 것에 비해 일반적으로 15~20분을 절약합니다. 가끔씩 하는 훈련 실행의 경우 이 시간 절약은 총 GPU 임대의 상당한 비율을 나타낼 수 있습니다.

---

## 훈련 매개변수 구성

훈련 구성은 출력 품질과 훈련 기간 모두에 상당한 영향을 미칩니다. 아래 매개변수는 과도한 계산 없이 신뢰할 수 있는 결과를 생성하는 보수적인 시작점을 나타냅니다.

### 필수 매개변수

`training_config.toml`이라는 구성 파일을 생성합니다:

```toml
[model]
pretrained_model_name_or_path = "./models/sd/v1-5-pruned.safetensors"
v2 = false
v_parameterization = false

[dataset]
train_data_dir = "./training_data"
resolution = 512
batch_size = 2
enable_bucket = true
min_bucket_reso = 256
max_bucket_reso = 1024

[training]
output_dir = "./output"
output_name = "my_lora"
max_train_epochs = 10
learning_rate = 1e-4
unet_lr = 1e-4
text_encoder_lr = 5e-5
lr_scheduler = "cosine_with_restarts"
lr_warmup_steps = 100
network_dim = 32
network_alpha = 16
optimizer_type = "AdamW8bit"
mixed_precision = "fp16"
save_every_n_epochs = 2
save_model_as = "safetensors"
```

### 매개변수 설명

**resolution:** 목표 추론 해상도와 일치시킵니다. SD 1.5의 경우 512, SDXL의 경우 1024.

**batch_size:** 값이 높을수록 더 빠르게 훈련하지만 더 많은 VRAM이 필요합니다. 2로 시작하고 메모리가 허용하면 4로 늘립니다.

**max_train_epochs:** 하나의 에포크는 모델이 모든 훈련 이미지를 한 번 본다는 의미입니다. 대부분의 데이터셋에 10개의 에포크가 합리적인 시작점입니다.

**learning_rate:** 모델이 얼마나 적극적으로 업데이트되는지 제어합니다. 위의 값은 보수적입니다. 결과가 약하면 2e-4 또는 3e-4로 높여보십시오.

**network_dim 및 network_alpha:** LoRA 용량을 제어합니다. Dim 32와 alpha 16은 품질과 파일 크기의 균형을 맞춥니다. 더 높은 차원(64, 128)은 더 많은 디테일을 캡처할 수 있지만 더 큰 파일을 생성하고 과적합의 위험이 있습니다.

**optimizer_type:** AdamW8bit는 품질에 미치는 영향을 최소화하면서 메모리 사용량을 크게 줄입니다. SDXL을 훈련하는 24GB 카드에 필수적입니다.

**mixed_precision:** FP16 훈련은 FP32에 비해 메모리 요구 사항을 절반으로 줄입니다. 대부분의 사용 사례에서 품질에 미치는 영향은 무시할 수 있습니다.

### 하드웨어에 맞게 조정

24GB VRAM의 RTX 4090의 경우:

- batch_size = 4는 일반적으로 SD 1.5에 안전합니다
- batch_size = 2는 SDXL에

24GB VRAM의 RTX 3090의 경우:

- batch_size = 2는 SD 1.5에
- batch_size = 1은 SDXL에 (그래디언트 체크포인팅 활성화)

40GB VRAM의 A100의 경우:

- batch_size = 6-8은 SD 1.5에
- batch_size = 4는 SDXL에

더 높은 배치 크기는 총 훈련 시간을 비례적으로 줄입니다. 배치 크기를 두 배로 늘리면 필요한 최적화 단계 수가 대략 절반으로 줄어듭니다.

![학습률, 배치 크기 및 네트워크 차원 매개변수가 있는 LoRA 훈련 구성 파일을 표시하는 코드 편집기](../_images/terminal-screenshot-code-editor.png)

---

## 훈련 실행

환경이 구성되고 매개변수가 설정되면 훈련을 시작합니다:

```bash
accelerate launch --num_cpu_threads_per_process=4 train_network.py \
  --config_file="./training_config.toml" \
  --logging_dir="./logs"
```

### 진행 상황 모니터링

훈련 출력은 손실 값과 진행 정보를 표시합니다:

```
epoch 1/10, step 50/500, loss=0.0823
epoch 1/10, step 100/500, loss=0.0756
epoch 1/10, step 150/500, loss=0.0691
...
```

**주의해야 할 사항:**

손실은 일반적으로 처음 몇 에포크 동안 감소한 다음 안정화되어야 합니다. 일반적인 훈련 실행은 다음을 보여줄 수 있습니다:

- 에포크 1: 손실 약 0.08-0.10
- 에포크 5: 손실 약 0.05-0.07
- 에포크 10: 손실 약 0.04-0.06

초기 감소 후 손실이 증가하면 모델이 과적합될 수 있습니다. 처음부터 손실이 평평하게 유지되면 학습률이 너무 낮을 수 있습니다.

### 체크포인팅

구성은 2개의 에포크마다 체크포인트를 저장합니다. 이러한 중간 저장은 두 가지 목적을 수행합니다:

1. **복구.** 훈련이 충돌하거나 조기에 종료해야 하는 경우 마지막 체크포인트에서 재개할 수 있습니다.

2. **선택.** 다른 에포크는 때때로 다른 특성을 생성합니다. 에포크 6이 개념을 잘 캡처하는 반면 에포크 10은 과적합될 수 있습니다. 체크포인트가 있으면 테스트하고 선택할 수 있습니다.

### 예상 훈련 시간

위 구성으로 50개 이미지 SD 1.5 LoRA의 경우:

| GPU      | 대략적인 시간 |
| -------- | ------------- |
| RTX 3090 | 90-120분      |
| RTX 4090 | 60-90분       |
| A100     | 45-60분       |

SDXL 훈련은 이 기간의 약 1.5배~2배가 필요합니다.

## LoRA 검증 및 테스트

훈련이 완료되면 출력 디렉토리에 .safetensors 파일이 생성됩니다. 프로젝트가 완료되었다고 간주하기 전에 이 파일을 테스트해야 합니다.

### 기본 검증

LoRA 파일을 로컬 머신 또는 Stable Diffusion WebUI를 실행하는 시스템으로 복사합니다:

```bash
# GPU 인스턴스에서 다운로드
scp user@gpu-instance-ip:~/sd-scripts/output/my_lora.safetensors ./
```

Automatic1111 WebUI에서 파일을 `models/Lora` 디렉토리에 배치합니다. ComfyUI의 경우 `models/loras` 디렉토리를 사용합니다.

### 테스트 방법론

다음 요소를 변경하면서 일련의 테스트 이미지를 생성합니다:

**LoRA 가중치:** 0.5, 0.7, 0.8 및 1.0 강도에서 테스트합니다. 일부 LoRA는 전체 강도 이하에서 가장 잘 작동합니다.

**프롬프트 위치:** 프롬프트의 다른 위치에 트리거 단어를 포함합니다. 시작, 중간 및 끝 위치는 미묘하게 다른 결과를 생성할 수 있습니다.

**네거티브 프롬프트:** 네거티브 프롬프트에 개념을 포함하거나 포함하지 않고 테스트합니다. 때때로 트리거를 네거티브에 추가하고 낮은 가중치를 사용하면 흥미로운 반전이 생성됩니다.

**다른 seed 값:** 일관된 패턴과 무작위 변동을 구별하기 위해 각 구성에 최소 5개의 다른 seed를 사용합니다.

### 품질 평가

다음 기준에 따라 결과를 평가합니다:

**개념 정확도:** 생성된 출력이 훈련 개념을 반영합니까? 얼굴을 훈련했다면 그 얼굴을 인식할 수 있습니까?

**통합:** LoRA 개념이 다른 프롬프트 요소와 자연스럽게 통합됩니까? 훈련된 캐릭터를 다양한 장면에 배치할 수 있습니까?

**아티팩트:** 일관되게 나타나는 반복 패턴, 부자연스러운 요소 또는 왜곡을 찾습니다. 이는 훈련 문제 또는 과적합을 나타냅니다.

**유연성:** 엣지 케이스를 테스트합니다. 캐릭터를 훈련했다면 다른 나이로 묘사할 수 있습니까? 다른 의상으로? 다양한 행동을 수행하면서?

결과가 만족스럽지 않은 경우 일반적인 해결책은 다음과 같습니다:

- 더 많은 에포크 동안 훈련 (과소적합)
- 더 적은 에포크 동안 훈련 (과적합)
- 학습률 조정
- 캡션 품질 개선
- 더 다양한 훈련 이미지 추가

![다양한 LoRA 강도 값에서 Stable Diffusion 출력을 보여주는 비교 그리드, AI 생성 이미지의 품질 차이를 보여줌](../_images/side-by-side-comparison.png)

---

## 비용 최적화 전략

5달러 훈련 실행과 20달러 훈련 실행의 차이는 종종 제공업체 선택보다 워크플로우 효율성에 달려 있습니다.

### 업로드 전 데이터셋 준비

GPU 임대를 시작하기 전에 로컬 머신에서 모든 데이터셋 큐레이션, 자르기 및 캡션 작성을 완료합니다. 파일을 수동으로 검토하고 이름을 바꾸는 데 시간당 $0.70를 지불하는 것은 해당 하드웨어의 비싼 사용입니다.

임대 시작 전 체크리스트:

- 모든 이미지가 적절한 종횡비로 자르기됨
- 모든 캡션이 작성되고 검토됨
- 데이터셋이 올바른 폴더 구조로 구성됨
- 훈련 구성 파일이 준비됨
- 테스트 명령이 작성되고 붙여넣기 준비됨

### 일괄 훈련

여러 LoRA가 필요한 경우 단일 세션에서 훈련합니다. 환경 설정 및 모델 다운로드의 고정 비용이 모든 훈련 실행에 분산됩니다.

예를 들어, 세 개의 별도 LoRA 훈련:

- 세 개의 별도 세션: 3 × (20분 설정 + 90분 훈련) = 330분
- 하나의 일괄 세션: 20분 설정 + (3 × 90분 훈련) = 290분

40분 절약은 약 15%의 비용 절감을 나타냅니다.

### 체크포인트 테스트 전략

에포크 15까지 훈련하고 좋은 결과를 기대하는 대신 다음을 고려하십시오:

1. 에포크 6까지 훈련 (전체 훈련 시간의 약 60%)
2. 체크포인트 테스트
3. 만족스러우면 중지하고 남은 GPU 시간 절약
4. 과소적합인 경우 체크포인트에서 훈련 계속

이 접근 방식은 종종 예상보다 일찍 좋은 결과를 잡아내어 총 비용을 줄입니다.

### 즉시 종료

GPU 과금은 일반적으로 인스턴스를 명시적으로 중지할 때까지 계속됩니다. 출력 파일을 복사한 후 즉시 세션을 닫습니다. 밤새 잊어버린 실행 중인 인스턴스는 시간당 $0.70에서 프로젝트 비용에 12달러를 추가합니다.

### 제공업체 선택 타이밍

GPU 가용성과 가격은 수요에 따라 변동합니다. 비수기 시간(예: 미국 시간대의 평일 아침)에 훈련하면 종종 주말 저녁보다 더 나은 가격과 GPU 가용성을 제공합니다.

---

## 일반적인 문제 및 해결방법

### CUDA 메모리 부족

**증상:** "CUDA out of memory" 오류와 함께 훈련이 충돌합니다.

**해결방법:**

- 구성에서 batch_size 줄이기
- `gradient_checkpointing = true`를 추가하여 그래디언트 체크포인팅 활성화
- 해상도 낮추기 (출력 품질에 영향을 미치지만)
- 더 많은 VRAM을 가진 GPU 사용

### 훈련 손실이 감소하지 않음

**증상:** 손실 값이 훈련 내내 평평하게 유지되거나 무작위로 변동합니다.

**해결방법:**

- 학습률 높이기 (2e-4 또는 3e-4 시도)
- 캡션이 이미지를 정확하게 설명하는지 확인
- 이미지가 올바르게 포맷되고 읽을 수 있는지 확인
- 기본 모델 경로가 올바른지 확인

### LoRA가 생성에 영향을 미치지 않음

**증상:** LoRA가 활성화되거나 비활성화되어도 생성된 이미지가 동일하게 보입니다.

**해결방법:**

- LoRA 파일이 UI의 올바른 디렉토리에 있는지 확인
- 트리거 단어가 훈련 캡션에서 사용한 것과 일치하는지 확인
- LoRA 가중치/강도 설정 높이기
- 훈련에서 다른 체크포인트 시도

### LoRA 과적합 및 유연하지 않음

**증상:** LoRA가 훈련 이미지를 거의 정확하게 생성하지만 다양한 프롬프트에서는 실패합니다.

**해결방법:**

- 더 적은 에포크 동안 훈련
- network_dim 값 줄이기
- 훈련 데이터셋에 더 많은 다양성 추가
- 학습률 낮추기

### 느린 훈련 속도

**증상:** 훈련이 예상 시간보다 훨씬 느리게 진행됩니다.

**해결방법:**

- GPU가 실제로 사용 중인지 확인 (nvidia-smi는 높은 GPU 사용률을 표시해야 함)
- xformers가 설치되었는지 확인
- mixed_precision이 활성화되었는지 확인
- 매우 높은 값을 사용하는 경우 network_dim 줄이기

---

## 자주 묻는 질문

### 임대 대신 자체 GPU를 사용하여 LoRA 모델을 훈련할 수 있나요?

예, RTX 3060 이상과 같이 최소 12GB VRAM을 가진 NVIDIA GPU가 있다면 가능합니다. 그러나 전기 비용, 하드웨어 마모 및 소비자 하드웨어에서 훨씬 긴 훈련 시간은 종종 가끔씩 하는 프로젝트에는 임대가 더 경제적인 선택이 되게 합니다. 시간당 $0.70에 2시간 훈련 실행은 더 느린 하드웨어에서 필요한 4~6시간 동안 전체 부하로 실행할 때 대부분의 가정용 설정이 소비하는 전기보다 적은 비용이 듭니다.

### 일반적인 LoRA 훈련 세션은 얼마나 걸리나요?

RTX 4090 또는 RTX 3090을 사용할 때 대부분의 LoRA 훈련 세션은 1~3시간 내에 완료됩니다. 정확한 기간은 데이터셋 크기, 훈련 에포크 수 및 배치 크기 구성에 따라 달라집니다. SDXL 모델은 동등한 훈련 실행에 대해 SD 1.5보다 약 50-100% 더 많은 시간이 필요합니다.

### LoRA 훈련에 필요한 최소 이미지 수는 얼마인가요?

15~20개의 이미지만으로도 합리적인 결과를 얻을 수 있습니다. 그러나 30~100개의 잘 캡션된 이미지를 포함하는 데이터셋이 일반적으로 더 나은 품질을 제공합니다. 이미지 품질과 캡션 정확도가 원시 수량보다 더 중요합니다. 잘 큐레이션된 30개 이미지 세트는 일반적으로 서둘러 조립된 100개 컬렉션보다 성능이 뛰어납니다.

### 어느 GPU 임대 제공업체가 LoRA 훈련에 가장 좋은 가치를 제공하나요?

Vast.ai는 일반적으로 RTX 4090 GPU에 대해 가장 낮은 시간당 요금을 제공하며, 종종 시간당 $0.35~$0.50입니다. GPUFlow는 암호화폐 결제 옵션과 신원 확인 요구 사항 없이 경쟁력 있는 가격을 제공합니다. RunPod는 GPU 임대 초보자에게 가장 간단한 인터페이스를 제공합니다. 모든 제공업체 및 현재 가격에 대한 자세한 비교는 [포괄적인 GPU 임대 가격 비교](/ko/gpu-rental-pricing-comparison-2026/)를 참조하십시오.

### 단일 세션에서 여러 LoRA 모델을 훈련하는 것이 더 비용 효율적인가요?

예. 하나의 연장된 세션에서 여러 LoRA를 일괄 훈련하면 반복되는 설정 시간을 제거하고 유휴 GPU 요금을 최소화합니다. 4시간 세션에서 3~5개의 LoRA 모델을 훈련하는 것은 일반적으로 별도의 임대에서 개별적으로 훈련하는 데 드는 비용의 절반 미만입니다.

### 훈련된 LoRA를 상업적으로 사용할 수 있나요?

이는 기본 모델의 라이선스에 따라 달라집니다. Stable Diffusion 1.5는 특정 제한이 있는 상업적 사용을 허용하는 CreativeML Open RAIL-M 라이선스를 사용합니다. SDXL도 유사한 관대한 라이선스를 가지고 있습니다. LoRA는 기본 모델의 제한을 상속합니다. 훈련 이미지에도 라이선스 요구 사항이 있을 수 있습니다—훈련에 사용하는 모든 이미지에 대한 적절한 권리가 있는지 확인하십시오.

---

## 결론

커스텀 LoRA 모델 훈련은 놀라울 정도로 접근 가능해졌습니다. 한때 상당한 하드웨어 투자가 필요했던 계산 장벽은 이제 몇 달러의 GPU 임대 비용에 불과합니다. 잘 준비된 데이터셋에 적용된 이 가이드에 설명된 기술은 첫 번째 시도에서 일관되게 사용 가능한 결과를 생성합니다.

중요한 성공 요소는 더 비싼 훈련 접근 방식에서와 변함없이 유지됩니다: 고품질 훈련 데이터, 적절한 매개변수 선택 및 결과의 신중한 검증. 아무리 많은 계산 능력도 나쁜 소스 이미지나 잘못 구성된 훈련 실행을 보완하지 못합니다.

20~30개 이미지의 적당한 데이터셋으로 시작하십시오. 보수적인 설정으로 훈련하십시오. 더 큰 프로젝트로 확장하기 전에 결과를 철저히 테스트하십시오. 시도당 비용이 충분히 낮아서 반복이 실용적입니다—처음 몇 번의 훈련 실행을 프로덕션 출력이 아닌 학습 경험으로 취급하십시오.

모든 제공업체 유형 및 가격대에서 GPU 임대 옵션을 비교하는 분들을 위해, [GPU 임대 가격 비교](/ko/gpu-rental-pricing-comparison-2026/)는 소비자 GPU, 데이터센터 하드웨어 및 기업 클라우드 옵션에 대한 현재 요금을 제공합니다.

---

_이 가이드는 2026년 2월 12일에 마지막으로 업데이트되었습니다. GPU 임대 가격 및 훈련 도구 구성은 자주 변경됩니다. 훈련 프로젝트를 시작하기 전에 제공업체에 직접 현재 가격을 확인하십시오._
