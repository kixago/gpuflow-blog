---
title: "כיצד לאמן מודלים של Stable Diffusion LoRA בפחות מ-10 דולר"
description: "מדריך צעד אחר צעד לאימון מודלים מותאמים אישית של LoRA עבור Stable Diffusion באמצעות השכרת GPU. מדריך מלא המכסה בחירת GPU, הכנת מערך נתונים, הגדרת אימון ואופטימיזציית עלויות."
excerpt: "מדריך מעשי לאימון מודלים איכותיים של LoRA באמצעות השכרת GPU. מכסה בחירת ספקים, הגדרות וטכניקות לשמירה על עלויות מתחת ל-10 דולר."
pubDate: 2026-02-11
updatedDate: 2026-02-11
locale: "he"
category: "tutorials"
featured: false
draft: false
author: "צוות GPUFlow"
heroImage: "../_images/stable-diffusion-lora-training-guide.jpg"
heroImageAlt: "כרטיס גרפי של NVIDIA מותקן במעמד שרתים עם מאווררי קירור ותאורת LED נראים לעין"
faq:
  - question: "האם אני יכול לאמן מודלים של LoRA באמצעות ה-GPU שלי במקום לשכור?"
    answer: "כן, בתנאי שיש לך GPU של NVIDIA עם לפחות 12GB של VRAM, כמו RTX 3060 או טוב יותר. עם זאת, עלויות החשמל, בלאי החומרה וזמני האימון הארוכים משמעותית על חומרה ביתית הופכים לעתים קרובות את ההשכרה לבחירה כלכלית יותר לפרויקטים מדי פעם."
  - question: "כמה זמן נמשכת סשן אימון טיפוסי של LoRA?"
    answer: "רוב סשנים של אימון LoRA מסתיימים תוך שעה עד שלוש שעות בעת שימוש ב-RTX 4090 או RTX 3090. משך הזמן המדויק תלוי בגודל מערך הנתונים שלך, מספר האפוקים של האימון והגדרת גודל האצווה שלך."
  - question: "מה מספר התמונות המינימלי הנדרש לאימון LoRA?"
    answer: "ניתן להפיק תוצאות סבירות עם מעט כמו חמש עשרה עד עשרים תמונות. עם זאת, מערכי נתונים המכילים שלושים עד מאה תמונות עם כיתובים טובים בדרך כלל מניבים איכות טובה יותר. איכות התמונה ודיוק הכיתובים חשובים יותר מהכמות הגולמית."
  - question: "איזה ספק השכרת GPU מציע את התמורה הטובה ביותר לאימון LoRA?"
    answer: "Vast.ai בדרך כלל מציע את התעריפים השעתיים הנמוכים ביותר עבור GPU מסוג RTX 4090. GPUFlow מספק תמחור תחרותי עם אפשרויות תשלום במטבעות קריפטוגרפיים וללא דרישות אימות זהות. RunPod מציע את הממשק הפשוט ביותר למשתמשים חדשים בהשכרת GPU."
  - question: "האם זה משתלם יותר לאמן מספר מודלים של LoRA בסשן אחד?"
    answer: "כן. אימון אצווה של מספר LoRAs בסשן מורחב אחד מבטל זמני הגדרה חוזרים ומצמצם את חיובי ה-GPU הבטלים. אימון של שלושה עד חמישה מודלים של LoRA בסשן של ארבע שעות עולה בדרך כלל פחות מחצי ממה שהיית מוציא על אימון כל אחד בנפרד."
---

# כיצד לאמן מודלים של Stable Diffusion LoRA בפחות מ-10 דולר

אימון מודלים מותאמים אישית של LoRA עבור Stable Diffusion הפך לאחת הדרכים הנגישות ביותר ליצירת תמונות שנוצרו על ידי בינה מלאכותית בהתאמה אישית. בין אם אתה רוצה לשחזר סגנון אמנותי ספציפי, ליצור פנים עקביות של דמויות או לכוונן את המודל על צילומי מוצרים, אימון LoRA מאפשר לך להשיג מטרות אלו ללא ההוצאה החישובית של כיוונון מודל מלא.

ההנחה הנפוצה היא שתהליך זה דורש חומרה מקומית יקרה או תקציבי מחשוב ענן משמעותיים. אף אחד מאלה אינו נכון. עם תמחור ההשכרה הנוכחי של GPU והגדרות אימון יעילות, ניתן לאמן מודלים של LoRA באיכות ייצור בפחות מעשרה דולר - לעתים קרובות הרבה פחות.

מדריך זה עובר דרך התהליך המלא: בחירת חומרה מתאימה, הכנת מערך נתוני האימון שלך, הגדרת פרמטרי האימון, ביצוע ריצת האימון ואימות התוצאות שלך. אהיה ספציפי לגבי עלויות בכל שלב, מכיוון שהבטחות מעורפלות של "אימון AI זול" לא עוזרות לאף אחד שמתכנן תקציב פרויקט בפועל.

**מה תצטרך לפני שתתחיל:**

- עשרים עד מאה תמונות אימון (עוד על קריטריוני בחירה בהמשך)
- היכרות בסיסית עם ממשקי שורת פקודה
- ארנק מטבעות קריפטוגרפיים או כרטיס אשראי לתשלום השכרת GPU
- כשעתיים עד ארבע שעות של זמן ממוקד
- תקציב של חמישה עד חמישה עשר דולר לריצת האימון הראשונה שלך

![פנים של מרכז נתונים מודרני עם שורות של שרתי GPU בעלי ביצועים גבוהים המשמשים לעומסי עבודה של למידת מכונה](../_images/data-center-with-person.jpg)

---

## תוכן עניינים

- [הבנת LoRA ומדוע זה חשוב](#הבנת-lora-ומדוע-זה-חשוב)
- [בחירת ה-GPU הנכון לאימון](#בחירת-ה-gpu-הנכון-לאימון)
- [השוואת ספקי השכרת GPU](#השוואת-ספקי-השכרת-gpu)
- [הכנת מערך נתוני האימון שלך](#הכנת-מערך-נתוני-האימון-שלך)
- [הגדרת סביבת האימון](#הגדרת-סביבת-האימון)
- [הגדרת פרמטרי אימון](#הגדרת-פרמטרי-אימון)
- [ביצוע ריצת האימון](#ביצוע-ריצת-האימון)
- [אימות ובדיקת ה-LoRA שלך](#אימות-ובדיקת-ה-lora-שלך)
- [אסטרטגיות לאופטימיזציית עלויות](#אסטרטגיות-לאופטימיזציית-עלויות)
- [בעיות נפוצות ופתרונות](#בעיות-נפוצות-ופתרונות)
- [שאלות נפוצות](#שאלות-נפוצות)

---

## הבנת LoRA ומדוע זה חשוב

LoRA, שמייצג Low-Rank Adaptation (התאמה בדרגה נמוכה), היא טכניקה לכיוונון עדין של רשתות עצביות גדולות על ידי אימון מספר קטן של פרמטרים נוספים במקום לשנות את כל המודל. מודל Stable Diffusion המקורי מכיל כמעט מיליארד פרמטרים. כיוונון עדין מלא ידרוש שינוי של כולם, מה שדורש זיכרון GPU משמעותי וזמני אימון מורחבים.

LoRA עוקפת בעיה זו על ידי הקפאת משקולות המודל המקורי ואימון מטריצות מתאם קטנות שמשנות את האופן שבו המודל מעבד מידע. קובץ LoRA טיפוסי הוא בין עשרה למאתיים מגה-בייט, בהשוואה לגודל של שניים עד שישה גיגה-בייט של צ'קפוינט מלא של Stable Diffusion.

ההשלכות המעשיות משמעותיות:

**יעילות זיכרון.** אימון LoRA דורש הרבה פחות זיכרון GPU VRAM מאשר כיוונון עדין מלא. GPU עם 24GB יכול לאמן בנוחות LoRAs עבור מודלים של SDXL שאחרת היו דורשים 40GB או יותר לכיוונון עדין מלא.

**מהירות אימון.** מכיוון שאתה מאמן פחות פרמטרים, כל אפוק אימון מסתיים מהר יותר. מה שעשוי לקחת שתים עשרה שעות לכיוונון עדין מלא יכול לעתים קרובות להתבצע בתשעים דקות עם LoRA.

**יכולת הרכבה.** ניתן לשלב מספר LoRAs בזמן היסק. אתה יכול להשתמש ב-LoRA אחד לסגנון אמנותי ובאחר לעקביות דמות, לערבב אותם בעוצמות שונות ללא אימון מחדש.

**אחסון והפצה.** גדלי קבצים קטנים הופכים LoRAs למעשיים לשיתוף ותחזוקה. אתה יכול לשמור באופן סביר עשרות LoRAs מתמחים ביד ללא חששות אחסון.

הפחתת העלויות מיעילויות אלה היא מה שמאפשר אימון מתחת לעשרה דולר. אתה שוכר חומרה יקרה לשעה עד שלוש שעות במקום שמונה עד עשרים וארבע שעות.

---

## בחירת ה-GPU הנכון לאימון

בחירת GPU כוללת איזון בין שלושה גורמים: קיבולת VRAM, מהירות אימון ועלות השכרה. האפשרות המינימלית הקיימא והבחירה האופטימלית נבדלות באופן משמעותי.

### דרישות VRAM

לאימון LoRA של Stable Diffusion 1.5, 12GB של VRAM הוא המינימום המעשי. ניתן לגרום לזה לעבוד עם 8GB על ידי הקטנת גדלי אצווה ורזולוציה, אך איכות האימון לעתים קרובות נפגעת.

לאימון LoRA של SDXL, 16GB הוא המינימום, כאשר 24GB מועדף מאוד. מודלים של SDXL גדולים ותובעניים יותר. ניסיון לאמן SDXL על VRAM לא מספיק מביא להחלפת זיכרון מתמדת, מאטה את התהליך באופן דרמטי ולעתים קרובות גורם לכשלי אימון.

### פשרות בין מהירות ועלות

GPUs יקרים יותר מאמנים מהר יותר, אבל עליית העלות לשעה לא תמיד מפחיתה באופן פרופורציונלי את העלות הכוללת של הפרויקט. שקול השוואה זו לאימון LoRA טיפוסי של SD 1.5:

| GPU         | VRAM | זמן אימון משוער | תעריף שעתי טיפוסי | עלות כוללת משוערת |
| ----------- | ---- | --------------- | ----------------- | ----------------- |
| RTX 3090    | 24GB | 2.5 שעות        | $0.50             | $1.25             |
| RTX 4090    | 24GB | 1.5 שעות        | $0.70             | $1.05             |
| RTX A6000   | 48GB | 1.5 שעות        | $0.80             | $1.20             |
| A100 (40GB) | 40GB | 1.0 שעות        | $1.50             | $1.50             |

ה-RTX 4090 בדרך כלל מציע את יעילות העלות הטובה ביותר. הוא מאמן כמעט באותה מהירות כמו GPUs של מרכזי נתונים בתעריפים שעתיים נמוכים משמעותית. ה-RTX 3090 נשאר קיים כשזמינות 4090 מוגבלת, עם עלויות כוללות גבוהות רק במעט.

לאימון LoRA של SDXL, החישובים משתנים מעט מכיוון שהמודל הגדול יותר נהנה יותר מ-VRAM נוסף ורוחב פס זיכרון. ה-A100 הופך לתחרותי יותר עבור פרויקטים מורכבים של SDXL שבהם האימון עשוי לקחת ארבע שעות או יותר על חומרה ביתית.

לניתוח מקיף של תמחור השכרת GPU בכל הספקים המרכזיים, כולל אפשרויות ענן ארגוניות ופלטפורמות שוק, ראה את [השוואת תמחור השכרת GPU המלאה שלנו לשנת 2026](/he/gpu-rental-pricing-comparison-2026/).

![כרטיס גרפי NVIDIA RTX 4090 עם מערכת קירור עם שלושה מאווררים המשמש בדרך כלל לאימון מודלים של בינה מלאכותית](../_images/nvidia-4090.jpg)

---

## השוואת ספקי השכרת GPU

שלושה ספקים ראויים לשיקול עבור עומסי עבודה של אימון LoRA. לכל אחד מאפיינים ייחודיים שחשובים בהתאם להעדפות התשלום שלך, רמת הנוחות הטכנית שלך ורגישות העלות שלך.

### Vast.ai

Vast.ai מפעילה שוק עמית לעמית שבו בעלי GPU פרטיים מציעים את החומרה שלהם להשכרה. מודל זה מייצר את המחירים הנמוכים ביותר בשוק, כאשר GPUs של RTX 4090 זמינים לעתים קרובות ב-$0.35 עד $0.60 לשעה.

הפשרה כוללת שונות. אמינות הספק נעה בין 97% ל-99.9% בהתאם למארח הפרטי. הזמינות משתנה בהתבסס על הביקוש. ייתכן שתצטרך לנסות מספר ספקים לפני שתמצא אחד עם מהירויות רשת מקובלות להעלאת מערך הנתונים שלך.

למשתמשים מנוסים שנוח להם להעריך מדדי ספקים, Vast.ai מציעה את עלויות האימון הנמוכות ביותר האפשריות. תקצב שלושים דקות נוספות להגדרה ראשונית והערכת ספק.

### RunPod

RunPod ממצבת את עצמה בין שווקים טהורים לספקי ענן ארגוניים. הפלטפורמה מציעה גם GPUs ממקורות קהילתיים וגם מופעי "Secure Cloud" ייעודיים עם ביצועים עקביים יותר.

התמחור מעט גבוה יותר מ-Vast.ai, בדרך כלל $0.59 לשעה לגישה ל-RTX 4090 ברמת Secure Cloud. הפלטפורמה מפצה עם הגדרה קלה יותר, תבניות מוגדרות מראש לעומסי עבודה נפוצים של בינה מלאכותית וזמינות צפויה יותר.

למשתמשים חדשים בהשכרת GPU או לאלה שמעריכים ממשקים פשוטים על פני אופטימיזציית עלות מינימלית, RunPod מייצגת אמצע הדרך הסביר.

### GPUFlow

GPUFlow מפעילה שוק עמית לעמית הבנוי על תשתית בלוקצ'יין, תוך שימוש בנאמנות חוזה חכם לעיבוד תשלומים. הפלטפורמה מקבלת תשלומים במטבעות קריפטוגרפיים ואינה דורשת אימות זהות.

התמחור נופל בדרך כלל בין Vast.ai ל-RunPod, עם גישה ל-RTX 4090 ב-$0.50 עד $0.80 לשעה. המאפיינים המבדילים הם פרטיות תשלום, הגדרה מיידית (בדרך כלל פחות משלושים שניות למופע פעיל) ועמלות פלטפורמה נמוכות יותר משווקים מתחרים.

למשתמשים שמעדיפים תשלומים במטבעות קריפטוגרפיים, מעריכים פרטיות עסקאות או רוצים להימנע מתהליכי אימות חשבון הנפוצים אצל ספקים מסורתיים, GPUFlow מספקת חלופה יעילה.

### סיכום ספקים

| ספק     | טווח מחירי RTX 4090      | זמן הגדרה | אפשרויות תשלום      | הכי טוב עבור           |
| ------- | ------------------------ | --------- | ------------------- | ---------------------- |
| Vast.ai | $0.35-0.60/שעה           | 5-15 דקות | כרטיס אשראי         | חיסכון מקסימלי בעלויות |
| RunPod  | $0.59/שעה (Secure Cloud) | 2-5 דקות  | כרטיס אשראי, קריפטו | קלות שימוש             |
| GPUFlow | $0.50-0.80/שעה           | 30 שניות  | קריפטו בלבד         | פרטיות, מהירות         |

## הכנת מערך נתוני האימון שלך

איכות מערך הנתונים קובעת את תוצאת האימון יותר מכל גורם אחר. סט מאוסף בקפידה של שלושים תמונות יניב תוצאות טובות יותר מאוסף של מאתיים תמונות שהורכב בחוסר זהירות.

### קריטריונים לבחירת תמונות

**עקביות.** כל התמונות צריכות לייצג את הקונספט שאתה רוצה שהמודל ילמד. אם אתה מאמן על פנים של אדם ספציפי, כל תמונה צריכה להראות בבירור את אותם פנים. אם אתה מאמן על סגנון אמנותי, כל תמונה צריכה להדגים את אותו סגנון.

**מגוון בתוך עקביות.** תוך שמירה על עקביות קונספטואלית, שנה את ההיבטים הטכניים. כלול זוויות שונות, תנאי תאורה, רקעים והקשרים. מגוון זה מלמד את המודל להכליל במקום להתאים יתר על המידה לקומפוזיציות ספציפיות.

**איכות טכנית.** השתמש בתמונות חדות וחשופות היטב. טשטוש תנועה, רעש, ארטיפקטים של דחיסה ותאורה גרועה - כל אלה הופכים לחלק ממה שהמודל לומד. אם תמונות האימון שלך מגורענות, התמונות שייווצרו יטו לגרעיניות.

**רזולוציה.** תמונות אימון צריכות להיות לפחות 512x512 פיקסלים עבור SD 1.5, ולפחות 1024x1024 עבור SDXL. תמונות מקור ברזולוציה גבוהה יותר מאפשרות לצינור האימון לחתוך ולשנות גודל ללא אובדן איכות.

### הנחיות לגודל מערך הנתונים

גודל מערך הנתונים האופטימלי תלוי במורכבות הקונספט:

**קונספטים פשוטים (פנים בודדות, סגנון בסיסי):** 20-40 תמונות
**קונספטים בינוניים (דמות עם תלבושות מרובות, סגנון מורכב):** 40-80 תמונות
**קונספטים מורכבים (סביבה מפורטת, סגנון משתנה מאוד):** 80-150 תמונות

יותר תמונות דורשות יותר שלבי אימון, מה שמגדיל את הזמן והעלות. התחל בקצה הנמוך של טווחים אלה בניסיונות הראשונים שלך.

### כתיבת כיתובים לתמונות שלך

כל תמונת אימון דורשת כיתוב טקסטואלי המתאר את תוכנה. כיתובים אלה מלמדים את המודל אילו קונספטים טקסטואליים לשייך לדפוסים החזותיים.

כיתובים יעילים הם ספציפיים ועקביים:

**כיתוב גרוע:** "אישה"
**כיתוב טוב יותר:** "צילום של שרה מילר, אישה עם שיער חום קצר ועיניים ירוקות, לובשת סוודר כחול"

**כיתוב גרוע:** "אמנות פנטזיה"
**כיתוב טוב יותר:** "ציור דיגיטלי בסגנון פנטזיה זוהרת, הכולל פטריות זוהרות ביער חשוך, עבודת קווים מפורטת, פלטת צבעים סגולה וכחולה תוססת"

מילת ההפעלה או הביטוי שאתה רוצה להשתמש בהם במהלך ההיסק צריכים להופיע בכל כיתוב. אם אתה רוצה להפעיל את ה-LoRA שלך עם "בסגנון פנטזיה זוהרת", הביטוי המדויק הזה צריך להופיע בכל כיתוב אימון.

ניתן לבצע כיתוב ידנית עבור מערכי נתונים קטנים. עבור אוספים גדולים יותר, כלים כמו BLIP או WD14 Tagger יכולים ליצור כיתובים ראשוניים שאתה לאחר מכן סוקר ומשפר.

![מבנה תיקיות מסודר המציג תמונות אימון לצד קבצי הטקסט של הכיתובים המתאימים שלהם לאימון LoRA](../_images/file-folder-organization.png)

### מבנה ספריות

ארגן את נתוני האימון שלך במבנה ספציפי שסקריפטי האימון מצפים לו:

```
training_data/
├── 10_concept_name/
│   ├── image001.jpg
│   ├── image001.txt
│   ├── image002.jpg
│   ├── image002.txt
│   └── ...
```

קידומת שם התיקייה (ה-"10" בדוגמה זו) מציינת כמה פעמים כל תמונה באותה תיקייה צריכה להיות חוזרת במהלך האימון. מספרים גבוהים יותר מגדילים את המשקל של אותן תמונות בתהליך האימון.

השם המופרד בקו תחתון אחרי המספר הופך למילת ההפעלה הברירת מחדל אם תבחר שלא להשתמש בכיתובים מותאמים אישית.

---

## הגדרת סביבת האימון

לאחר שמערך הנתונים שלך מוכן והשכרת ה-GPU מובטחת, השלב הבא הוא הגדרת סביבת האימון. שרשרת הכלים הסטנדרטית לאימון LoRA היא kohya_ss/sd-scripts, אוסף קוד פתוח של סקריפטי אימון המתוחזק על ידי הקהילה.

### הגדרת סביבה ראשונית

לאחר ההתחברות למופע ה-GPU המושכר שלך, תצטרך לשכפל את מאגר האימון ולהתקין תלויות. הפקודות הבאות מבססות את הסביבה הבסיסית:

```bash
# שכפל את מאגר סקריפטי האימון
git clone https://github.com/kohya-ss/sd-scripts.git
cd sd-scripts

# צור והפעל סביבה וירטואלית
python -m venv venv
source venv/bin/activate

# התקן תלויות
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
pip install xformers
```

התקנה זו בדרך כלל לוקחת חמש עד עשר דקות בהתאם למהירות הרשת. חבילת xformers היא אופציונלית אך מומלצת, מכיוון שהיא מפחיתה משמעותית את השימוש בזיכרון במהלך האימון.

### הורדת המודל הבסיסי

אימון LoRA דורש מודל בסיס של Stable Diffusion לאמן כנגדו. תצטרך להוריד אותו למופע שלך:

```bash
# צור ספריית מודלים
mkdir -p models/sd

# הורד Stable Diffusion 1.5 (כ-4GB)
wget -O models/sd/v1-5-pruned.safetensors \
  "https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned.safetensors"
```

לאימון SDXL, החלף את מודל הבסיס של SDXL, שהוא כ-6.5GB.

### העלאת נתוני האימון שלך

העבר את מערך הנתונים המוכן שלך למופע ה-GPU. רוב הספקים תומכים ב-SCP או SFTP:

```bash
# מהמחשב המקומי שלך
scp -r ./training_data user@gpu-instance-ip:~/sd-scripts/
```

לחלופין, אם מערך הנתונים שלך מאוחסן באחסון ענן, אתה יכול להוריד אותו ישירות למופע באמצעות wget או rclone.

### הגדרה ספציפית ל-GPUFlow

אם אתה משתמש ב-GPUFlow, הפלטפורמה מספקת סביבות מוגדרות מראש שמבטלות את רוב ההגדרה הידנית. לאחר ההתחברות דרך הטרמינל המבוסס אינטרנט:

```bash
# מופעי GPUFlow כוללים סביבת אימון מותקנת מראש
cd /workspace/sd-scripts

# העלה את מערך הנתונים שלך באמצעות ממשק האינטרנט או SCP
# סקריפטי האימון מוגדרים מראש ומוכנים לשימוש
```

הגדרה מראש זו בדרך כלל חוסכת חמש עשרה עד עשרים דקות בהשוואה להגדרת מופע ריק מאפס. עבור ריצות אימון מדי פעם, חיסכון זמן זה יכול לייצג אחוז משמעותי מסך השכרת ה-GPU שלך.

---

## הגדרת פרמטרי אימון

הגדרת האימון משפיעה באופן משמעותי הן על איכות הפלט והן על משך האימון. הפרמטרים להלן מייצגים נקודות התחלה שמרניות שמייצרות תוצאות אמינות ללא חישוב מופרז.

### פרמטרים חיוניים

צור קובץ הגדרות בשם `training_config.toml`:

```toml
[model]
pretrained_model_name_or_path = "./models/sd/v1-5-pruned.safetensors"
v2 = false
v_parameterization = false

[dataset]
train_data_dir = "./training_data"
resolution = 512
batch_size = 2
enable_bucket = true
min_bucket_reso = 256
max_bucket_reso = 1024

[training]
output_dir = "./output"
output_name = "my_lora"
max_train_epochs = 10
learning_rate = 1e-4
unet_lr = 1e-4
text_encoder_lr = 5e-5
lr_scheduler = "cosine_with_restarts"
lr_warmup_steps = 100
network_dim = 32
network_alpha = 16
optimizer_type = "AdamW8bit"
mixed_precision = "fp16"
save_every_n_epochs = 2
save_model_as = "safetensors"
```

### הסברי פרמטרים

**resolution:** התאם זאת לרזולוציית ההיסק היעד שלך. 512 עבור SD 1.5, 1024 עבור SDXL.

**batch_size:** ערכים גבוהים יותר מאמנים מהר יותר אך דורשים יותר VRAM. התחל עם 2, הגדל ל-4 אם הזיכרון מאפשר.

**max_train_epochs:** אפוק אחד אומר שהמודל רואה כל תמונת אימון פעם אחת. עשרה אפוקים היא נקודת התחלה סבירה לרוב מערכי הנתונים.

**learning_rate:** שולט בכמה המודל מתעדכן באגרסיביות. הערכים למעלה הם שמרניים. אם התוצאות חלשות, נסה להגדיל ל-2e-4 או 3e-4.

**network_dim ו-network_alpha:** אלה שולטים בקיבולת ה-LoRA. Dim 32 עם alpha 16 מאזן בין איכות לגודל קובץ. ממדים גבוהים יותר (64, 128) יכולים ללכוד יותר פרטים אבל מייצרים קבצים גדולים יותר ומסתכנים בהתאמת יתר.

**optimizer_type:** AdamW8bit מפחית את השימוש בזיכרון באופן משמעותי עם השפעה מינימלית על האיכות. חיוני לכרטיסים עם 24GB שמאמנים SDXL.

**mixed_precision:** אימון FP16 מחצה את דרישות הזיכרון בהשוואה ל-FP32. ההשפעה על האיכות זניחה ברוב המקרים.

### התאמה לחומרה שלך

עבור RTX 4090 עם 24GB VRAM:

- batch_size = 4 הוא בדרך כלל בטוח עבור SD 1.5
- batch_size = 2 עבור SDXL

עבור RTX 3090 עם 24GB VRAM:

- batch_size = 2 עבור SD 1.5
- batch_size = 1 עבור SDXL (הפעל gradient checkpointing)

עבור A100 עם 40GB VRAM:

- batch_size = 6-8 עבור SD 1.5
- batch_size = 4 עבור SDXL

גדלי אצווה גבוהים יותר מפחיתים את זמן האימון הכולל באופן פרופורציונלי. הכפלת גודל האצווה מחצה בערך את מספר שלבי האופטימיזציה הנדרשים.

![עורך קוד המציג קובץ הגדרות אימון LoRA עם פרמטרים לקצב למידה, גודל אצווה וממדי רשת](../_images/terminal-screenshot-code-editor.png)

---

## ביצוע ריצת האימון

עם הסביבה מוגדרת והפרמטרים מוכנים, התחל את האימון:

```bash
accelerate launch --num_cpu_threads_per_process=4 train_network.py \
  --config_file="./training_config.toml" \
  --logging_dir="./logs"
```

### מעקב אחר התקדמות

פלט האימון מציג ערכי אובדן ומידע על ההתקדמות:

```
epoch 1/10, step 50/500, loss=0.0823
epoch 1/10, step 100/500, loss=0.0756
epoch 1/10, step 150/500, loss=0.0691
...
```

**מה לחפש:**

האובדן בדרך כלל צריך לרדת במהלך האפוקים הראשונים, ואז להתייצב. ריצת אימון טיפוסית עשויה להראות:

- אפוק 1: אובדן סביב 0.08-0.10
- אפוק 5: אובדן סביב 0.05-0.07
- אפוק 10: אובדן סביב 0.04-0.06

אם האובדן עולה לאחר ירידה ראשונית, המודל עשוי להתאים יתר על המידה. אם האובדן נשאר שטוח מההתחלה, קצב הלמידה עשוי להיות נמוך מדי.

### נקודות ביקורת

ההגדרה שומרת נקודות ביקורת כל שני אפוקים. שמירות ביניים אלה משרתות שתי מטרות:

1. **התאוששות.** אם האימון קורס או שאתה צריך לסיים מוקדם, אתה יכול להמשיך מנקודת הביקורת האחרונה.

2. **בחירה.** אפוקים שונים לפעמים מייצרים מאפיינים שונים. אפוק 6 עשוי ללכוד את הקונספט שלך היטב בעוד אפוק 10 מתאים יתר על המידה. נקודות ביקורת מאפשרות לך לבדוק ולבחור.

### זמני אימון צפויים

עבור LoRA של SD 1.5 עם 50 תמונות עם ההגדרה שלמעלה:

| GPU      | זמן משוער   |
| -------- | ----------- |
| RTX 3090 | 90-120 דקות |
| RTX 4090 | 60-90 דקות  |
| A100     | 45-60 דקות  |

אימון SDXL דורש כ-1.5x עד 2x משך זמן אלה.

## אימות ובדיקת ה-LoRA שלך

השלמת האימון מייצרת קובץ .safetensors בספריית הפלט שלך. קובץ זה צריך בדיקה לפני שתוכל לראות את הפרויקט כמושלם.

### אימות בסיסי

העתק את קובץ ה-LoRA למחשב המקומי שלך או למערכת שמריצה Stable Diffusion WebUI:

```bash
# הורד ממופע ה-GPU
scp user@gpu-instance-ip:~/sd-scripts/output/my_lora.safetensors ./
```

ב-Automatic1111 WebUI, מקם את הקובץ בספריית `models/Lora`. עבור ComfyUI, השתמש בספריית `models/loras`.

### מתודולוגיית בדיקה

צור סדרה של תמונות בדיקה תוך שינוי הגורמים הבאים:

**משקל LoRA:** בדוק בעוצמה של 0.5, 0.7, 0.8 ו-1.0. חלק מה-LoRAs עובדים הכי טוב מתחת לעוצמה מלאה.

**מיקום בפרומפט:** כלול את מילת ההפעלה שלך במיקומים שונים בפרומפט. מיקומי התחלה, אמצע וסוף יכולים לייצר תוצאות שונות בעדינות.

**פרומפטים שליליים:** בדוק עם ובלי הקונספט שלך בפרומפטים שליליים. לפעמים הוספת מילת ההפעלה לשליליים ושימוש במשקל נמוך יוצרת היפוכים מעניינים.

**ערכי seed שונים:** השתמש בלפחות חמישה seeds שונים לכל הגדרה כדי להבחין בין דפוסים עקביים לבין שונות אקראית.

### הערכת איכות

הערך את התוצאות שלך מול הקריטריונים הבאים:

**דיוק קונספט:** האם הפלט שנוצר משקף את קונספט האימון שלך? אם אימנת על פנים, האם הפנים האלה ניתנות לזיהוי?

**אינטגרציה:** האם קונספט ה-LoRA משתלב באופן טבעי עם אלמנטים אחרים בפרומפט? האם אתה יכול למקם את הדמות המאומנת שלך בסצנות מגוונות?

**ארטיפקטים:** חפש דפוסים חוזרים, אלמנטים לא טבעיים או עיוותים שמופיעים באופן עקבי. אלה מצביעים על בעיות אימון או התאמת יתר.

**גמישות:** בדוק מקרי קצה. אם אימנת דמות, האם ניתן לתאר אותה בגילאים שונים? בלבוש שונה? מבצעת פעולות שונות?

אם התוצאות אינן מספקות, תרופות נפוצות כוללות:

- אימון ליותר אפוקים (התאמת חסר)
- אימון לפחות אפוקים (התאמת יתר)
- התאמת קצב הלמידה
- שיפור איכות הכיתובים
- הוספת תמונות אימון מגוונות יותר

![רשת השוואה המציגה פלטים של Stable Diffusion בערכי עוצמת LoRA שונים המדגימה הבדלי איכות בתמונות שנוצרו על ידי בינה מלאכותית](../_images/side-by-side-comparison.png)

---

## אסטרטגיות לאופטימיזציית עלויות

ההבדל בין ריצת אימון של חמישה דולר לריצת אימון של עשרים דולר לעתים קרובות מסתכם ביעילות זרימת העבודה ולא בבחירת הספק.

### הכנת מערך נתונים לפני העלאה

השלם את כל אוצרות מערך הנתונים, החיתוך והכיתוב במחשב המקומי שלך לפני תחילת השכרת ה-GPU. לשלם $0.70 לשעה כדי לסקור ולשנות שמות קבצים באופן ידני הוא שימוש יקר בחומרה זו.

רשימת בדיקה לפני תחילת ההשכרה:

- כל התמונות חתוכות ליחסי גובה-רוחב מתאימים
- כל הכיתובים נכתבו ונבדקו
- מערך הנתונים מאורגן במבנה התיקיות הנכון
- קובץ הגדרות האימון מוכן
- פקודות בדיקה כתובות ומוכנות להדבקה

### אימון אצווה

אם אתה צריך מספר LoRAs, אמן אותם בסשן אחד. העלויות הקבועות של הגדרת הסביבה והורדת המודל מתפרשות על כל ריצות האימון.

לדוגמה, אימון שלושה LoRAs נפרדים:

- שלושה סשנים נפרדים: 3 × (20 דקות הגדרה + 90 דקות אימון) = 330 דקות
- סשן אצווה אחד: 20 דקות הגדרה + (3 × 90 דקות אימון) = 290 דקות

החיסכון של ארבעים דקות מייצג הפחתת עלויות של כ-15%.

### אסטרטגיית בדיקת נקודות ביקורת

במקום לאמן עד אפוק 15 ולקוות לתוצאות טובות, שקול:

1. אמן עד אפוק 6 (כ-60% מזמן האימון המלא)
2. בדוק את נקודת הביקורת
3. אם מספק, עצור וחסוך את שאר זמן ה-GPU
4. אם יש התאמת חסר, המשך באימון מנקודת הביקורת

גישה זו לעתים קרובות תופסת תוצאות טובות מוקדם מהצפוי, מפחיתה עלויות כוללות.

### סיים מיידית

חיוב GPU בדרך כלל ממשיך עד שאתה עוצר את המופע באופן מפורש. סגור את הסשן שלך מיד לאחר העתקת קבצי הפלט שלך. מופע פועל שנשכח במשך הלילה ב-$0.70 לשעה מוסיף שנים עשר דולר לעלות הפרויקט שלך.

### תזמון בחירת ספק

זמינות ותמחור GPU משתנים בהתבסס על הביקוש. אימון בשעות מחוץ לשיא (בקרי ימי חול באזורי הזמן של ארה"ב, לדוגמה) לעתים קרובות מספק תמחור וזמינות GPU טובים יותר מערבי סוף שבוע.

---

## בעיות נפוצות ופתרונות

### CUDA Out of Memory

**סימפטום:** האימון קורס עם שגיאת "CUDA out of memory".

**פתרונות:**

- הפחת את batch_size בהגדרות
- הפעל gradient checkpointing על ידי הוספת `gradient_checkpointing = true`
- הורד את הרזולוציה (אם כי זה משפיע על איכות הפלט)
- השתמש ב-GPU עם יותר VRAM

### אובדן האימון לא יורד

**סימפטום:** ערכי האובדן נשארים שטוחים או משתנים באקראיות לאורך האימון.

**פתרונות:**

- הגדל את קצב הלמידה (נסה 2e-4 או 3e-4)
- בדוק שהכיתובים מתארים נכון את התמונות
- וודא שהתמונות מעוצבות נכון וקריאות
- ודא שנתיב המודל הבסיסי נכון

### ל-LoRA אין השפעה על היצירה

**סימפטום:** תמונות שנוצרו נראות זהות עם LoRA מופעל או מושבת.

**פתרונות:**

- וודא שקובץ ה-LoRA נמצא בספרייה הנכונה עבור הממשק שלך
- בדוק שמילות ההפעלה תואמות למה שהשתמשת בכיתובי האימון
- הגדל את הגדרת המשקל/עוצמה של ה-LoRA
- נסה נקודת ביקורת שונה מהאימון

### LoRA עם התאמת יתר ולא גמיש

**סימפטום:** ה-LoRA מייצר את תמונות האימון כמעט בדיוק, אבל נכשל עם פרומפטים מגוונים.

**פתרונות:**

- אמן לפחות אפוקים
- הפחת את ערך network_dim
- הוסף יותר מגוון למערך נתוני האימון
- הפחת את קצב הלמידה

### מהירות אימון איטית

**סימפטום:** האימון מתקדם הרבה יותר לאט מהזמנים הצפויים.

**פתרונות:**

- וודא שה-GPU אכן בשימוש (nvidia-smi צריך להראות ניצול GPU גבוה)
- ודא ש-xformers מותקן
- בדוק ש-mixed_precision מופעל
- הפחת את network_dim אם משתמש בערכים גבוהים מאוד

---

## שאלות נפוצות

### האם אני יכול לאמן מודלים של LoRA באמצעות ה-GPU שלי במקום לשכור?

כן, בתנאי שיש לך GPU של NVIDIA עם לפחות 12GB של VRAM, כמו RTX 3060 או טוב יותר. עם זאת, עלויות החשמל, בלאי החומרה וזמני האימון הארוכים משמעותית על חומרה ביתית הופכים לעתים קרובות את ההשכרה לבחירה כלכלית יותר לפרויקטים מדי פעם. ריצת אימון של שעתיים ב-$0.70 לשעה עולה פחות מהחשמל שרוב ההתקנות הביתיות צורכות כשהן פועלות בעומס מלא במשך ארבע עד שש שעות הנדרשות על חומרה איטית יותר.

### כמה זמן נמשכת סשן אימון טיפוסי של LoRA?

רוב סשני אימון LoRA מסתיימים תוך שעה עד שלוש שעות בעת שימוש ב-RTX 4090 או RTX 3090. משך הזמן המדויק תלוי בגודל מערך הנתונים שלך, מספר אפוקי האימון והגדרת גודל האצווה שלך. מודלים של SDXL דורשים כ-50-100% יותר זמן מ-SD 1.5 עבור ריצות אימון שוות ערך.

### מה מספר התמונות המינימלי הנדרש לאימון LoRA?

ניתן להפיק תוצאות סבירות עם מעט כמו חמש עשרה עד עשרים תמונות. עם זאת, מערכי נתונים המכילים שלושים עד מאה תמונות עם כיתובים טובים בדרך כלל מניבים איכות טובה יותר. איכות התמונה ודיוק הכיתובים חשובים יותר מהכמות הגולמית. סט מאוסף היטב של שלושים תמונות בדרך כלל עולה על אוסף ממהר של מאה.

### איזה ספק השכרת GPU מציע את התמורה הטובה ביותר לאימון LoRA?

Vast.ai בדרך כלל מציע את התעריפים השעתיים הנמוכים ביותר עבור GPUs מסוג RTX 4090, לעתים קרובות $0.35 עד $0.50 לשעה. GPUFlow מספק תמחור תחרותי עם אפשרויות תשלום במטבעות קריפטוגרפיים וללא דרישות אימות זהות. RunPod מציע את הממשק הפשוט ביותר למשתמשים חדשים בהשכרת GPU. להשוואה מפורטת של כל הספקים והתמחור הנוכחי, ראה את [השוואת תמחור השכרת GPU המקיפה שלנו](/he/gpu-rental-pricing-comparison-2026/).

### האם זה משתלם יותר לאמן מספר מודלים של LoRA בסשן אחד?

כן. אימון אצווה של מספר LoRAs בסשן מורחב אחד מבטל זמני הגדרה חוזרים ומצמצם את חיובי ה-GPU הבטלים. אימון של שלושה עד חמישה מודלים של LoRA בסשן של ארבע שעות עולה בדרך כלל פחות מחצי ממה שהיית מוציא על אימון כל אחד בנפרד בהשכרות נפרדות.

### האם אני יכול להשתמש ב-LoRAs מאומנים למטרות מסחריות?

זה תלוי ברישיון של מודל הבסיס שלך. Stable Diffusion 1.5 משתמש ברישיון CreativeML Open RAIL-M, המאפשר שימוש מסחרי עם הגבלות מסוימות. ל-SDXL רישוי מתירני דומה. ה-LoRA שלך יורש הגבלות ממודל הבסיס שלו. תמונות אימון עשויות גם לשאת דרישות רישוי - ודא שיש לך את הזכויות המתאימות לכל תמונה שאתה משתמש בה לאימון.

---

## סיכום

אימון מודלים מותאמים אישית של LoRA הפך לנגיש באופן יוצא דופן. המחסומים החישוביים שפעם דרשו השקעה משמעותית בחומרה מסתכמים כעת בכמה דולרים בדמי השכרת GPU. הטכניקות המתוארות במדריך זה, כשהן מיושמות על מערך נתונים מוכן היטב, מייצרות באופן עקבי תוצאות שמישות בניסיון הראשון.

גורמי ההצלחה הקריטיים נשארים ללא שינוי מגישות אימון יקרות יותר: נתוני אימון איכותיים, בחירת פרמטרים מתאימה ואימות קפדני של תוצאות. אין כמות של כוח חישובי שמפצה על תמונות מקור גרועות או ריצות אימון שהוגדרו בצורה שגויה.

התחל עם מערך נתונים צנוע של עשרים עד שלושים תמונות. אמן בהגדרות שמרניות. בדוק את התוצאות שלך ביסודיות לפני הרחבה לפרויקטים גדולים יותר. העלות לניסיון נמוכה מספיק כדי שאיטרציה תהיה מעשית - התייחס לריצות האימון הראשונות שלך כחוויות למידה ולא כתפוקות ייצור.

לאלה המשווים אפשרויות השכרת GPU בכל סוגי הספקים ונקודות המחיר, [השוואת תמחור השכרת GPU שלנו](/he/gpu-rental-pricing-comparison-2026/) מספקת תעריפים נוכחיים עבור GPUs ביתיים, חומרת מרכזי נתונים ואפשרויות ענן ארגוניות.

---

_מדריך זה עודכן לאחרונה ב-12 בפברואר 2026. תמחור השכרת GPU והגדרות כלי אימון משתנים לעתים קרובות. אמת את התמחור הנוכחי עם הספקים ישירות לפני התחייבות לפרויקט אימון._
