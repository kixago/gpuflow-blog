---
title: "10 डॉलर से कम में Stable Diffusion LoRA मॉडल कैसे ट्रेन करें"
description: "किराए पर GPU का उपयोग करके Stable Diffusion के लिए कस्टम LoRA मॉडल ट्रेन करने की चरण-दर-चरण गाइड। GPU चयन, डेटासेट तैयारी, ट्रेनिंग कॉन्फ़िगरेशन और लागत अनुकूलन को कवर करने वाला संपूर्ण ट्यूटोरियल।"
excerpt: "GPU किराए का उपयोग करके उच्च-गुणवत्ता वाले LoRA मॉडल ट्रेन करने के लिए व्यावहारिक ट्यूटोरियल। प्रदाता चयन, कॉन्फ़िगरेशन और कुल लागत को 10 डॉलर से कम रखने की तकनीकों को कवर करता है।"
pubDate: 2026-02-11
updatedDate: 2026-02-11
locale: "hi"
category: "tutorials"
featured: false
draft: false
author: "GPUFlow टीम"
heroImage: "../_images/stable-diffusion-lora-training-guide.jpg"
heroImageAlt: "कूलिंग फैन और LED लाइटिंग के साथ सर्वर रैक में स्थापित NVIDIA ग्राफिक्स कार्ड"
faq:
  - question: "क्या मैं किराए के बजाय अपने GPU का उपयोग करके LoRA मॉडल ट्रेन कर सकता हूं?"
    answer: "हां, बशर्ते आपके पास कम से कम 12GB VRAM वाला NVIDIA GPU हो, जैसे RTX 3060 या बेहतर। हालांकि, बिजली की लागत, हार्डवेयर की टूट-फूट, और कंज्यूमर हार्डवेयर पर काफी लंबा ट्रेनिंग समय अक्सर कभी-कभार प्रोजेक्ट्स के लिए किराए को अधिक किफायती विकल्प बनाता है।"
  - question: "एक सामान्य LoRA ट्रेनिंग सेशन में कितना समय लगता है?"
    answer: "RTX 4090 या RTX 3090 का उपयोग करते समय अधिकांश LoRA ट्रेनिंग सेशन एक से तीन घंटे के भीतर पूरे हो जाते हैं। सटीक अवधि आपके डेटासेट के आकार, ट्रेनिंग epochs की संख्या और आपके batch size कॉन्फ़िगरेशन पर निर्भर करती है।"
  - question: "LoRA ट्रेनिंग के लिए न्यूनतम कितनी इमेज आवश्यक हैं?"
    answer: "आप पंद्रह से बीस इमेज के साथ भी उचित परिणाम प्राप्त कर सकते हैं। हालांकि, तीस से सौ अच्छी तरह से कैप्शन की गई इमेज वाले डेटासेट आमतौर पर बेहतर गुणवत्ता देते हैं। इमेज की गुणवत्ता और कैप्शन की सटीकता कच्ची मात्रा से अधिक महत्वपूर्ण है।"
  - question: "LoRA ट्रेनिंग के लिए कौन सा GPU किराया प्रदाता सबसे अच्छा मूल्य प्रदान करता है?"
    answer: "Vast.ai आमतौर पर RTX 4090 GPU के लिए सबसे कम प्रति घंटा दरें प्रदान करता है। GPUFlow क्रिप्टोकरेंसी भुगतान विकल्पों और बिना पहचान सत्यापन आवश्यकताओं के साथ प्रतिस्पर्धी मूल्य निर्धारण प्रदान करता है। RunPod GPU किराए में नए उपयोगकर्ताओं के लिए सबसे सरल इंटरफ़ेस प्रदान करता है।"
  - question: "क्या एक ही सेशन में कई LoRA मॉडल ट्रेन करना अधिक लागत-प्रभावी है?"
    answer: "हां। एक विस्तारित सेशन में कई LoRA को बैच ट्रेनिंग करने से बार-बार सेटअप समय समाप्त हो जाता है और निष्क्रिय GPU शुल्क कम हो जाते हैं। चार घंटे के सेशन में तीन से पांच LoRA मॉडल ट्रेन करने की लागत आमतौर पर उन्हें अलग-अलग ट्रेन करने में खर्च होने वाली राशि की आधी से भी कम होती है।"
---

# 10 डॉलर से कम में Stable Diffusion LoRA मॉडल कैसे ट्रेन करें

Stable Diffusion के लिए कस्टम LoRA मॉडल ट्रेन करना व्यक्तिगत AI-जनरेटेड इमेजरी बनाने के सबसे सुलभ तरीकों में से एक बन गया है। चाहे आप किसी विशिष्ट कलात्मक शैली को पुनरुत्पादित करना चाहते हों, सुसंगत चरित्र चेहरे उत्पन्न करना चाहते हों, या उत्पाद फोटोग्राफी पर मॉडल को फाइन-ट्यून करना चाहते हों, LoRA ट्रेनिंग आपको पूर्ण मॉडल फाइन-ट्यूनिंग के कम्प्यूटेशनल खर्च के बिना इन लक्ष्यों को प्राप्त करने की अनुमति देती है।

आम धारणा यह है कि इस प्रक्रिया के लिए या तो महंगे स्थानीय हार्डवेयर या पर्याप्त क्लाउड कंप्यूटिंग बजट की आवश्यकता होती है। दोनों ही सत्य नहीं हैं। वर्तमान GPU किराया मूल्य निर्धारण और कुशल ट्रेनिंग कॉन्फ़िगरेशन के साथ, आप दस डॉलर से कम में उत्पादन-गुणवत्ता वाले LoRA मॉडल ट्रेन कर सकते हैं—अक्सर काफी कम में।

यह गाइड पूरी प्रक्रिया के माध्यम से चलती है: उपयुक्त हार्डवेयर का चयन, अपना ट्रेनिंग डेटासेट तैयार करना, ट्रेनिंग पैरामीटर कॉन्फ़िगर करना, ट्रेनिंग रन निष्पादित करना, और अपने परिणामों को मान्य करना। मैं प्रत्येक चरण में लागत के बारे में विशिष्ट रहूंगा, क्योंकि "किफायती AI ट्रेनिंग" के अस्पष्ट वादे वास्तविक प्रोजेक्ट बजट की योजना बनाने वाले किसी भी व्यक्ति की मदद नहीं करते।

**शुरू करने से पहले आपको क्या चाहिए:**

- बीस से सौ ट्रेनिंग इमेज (चयन मानदंड पर नीचे और अधिक)
- कमांड-लाइन इंटरफेस से बुनियादी परिचितता
- GPU किराया भुगतान के लिए क्रिप्टोकरेंसी वॉलेट या क्रेडिट कार्ड
- लगभग दो से चार घंटे का केंद्रित समय
- आपके पहले ट्रेनिंग रन के लिए पांच से पंद्रह डॉलर का बजट

![मशीन लर्निंग वर्कलोड के लिए उपयोग किए जाने वाले उच्च-प्रदर्शन GPU सर्वर की पंक्तियों के साथ आधुनिक डेटा सेंटर इंटीरियर](../_images/data-center-with-person.jpg)

---

## विषय सूची

- [LoRA को समझना और यह क्यों महत्वपूर्ण है](#lora-को-समझना-और-यह-क्यों-महत्वपूर्ण-है)
- [ट्रेनिंग के लिए सही GPU का चयन](#ट्रेनिंग-के-लिए-सही-gpu-का-चयन)
- [GPU किराया प्रदाता तुलना](#gpu-किराया-प्रदाता-तुलना)
- [अपना ट्रेनिंग डेटासेट तैयार करना](#अपना-ट्रेनिंग-डेटासेट-तैयार-करना)
- [ट्रेनिंग वातावरण सेट करना](#ट्रेनिंग-वातावरण-सेट-करना)
- [ट्रेनिंग पैरामीटर कॉन्फ़िगर करना](#ट्रेनिंग-पैरामीटर-कॉन्फ़िगर-करना)
- [ट्रेनिंग रन निष्पादित करना](#ट्रेनिंग-रन-निष्पादित-करना)
- [अपने LoRA को मान्य और परीक्षण करना](#अपने-lora-को-मान्य-और-परीक्षण-करना)
- [लागत अनुकूलन रणनीतियां](#लागत-अनुकूलन-रणनीतियां)
- [सामान्य समस्याएं और समाधान](#सामान्य-समस्याएं-और-समाधान)
- [अक्सर पूछे जाने वाले प्रश्न](#अक्सर-पूछे-जाने-वाले-प्रश्न)

---

## LoRA को समझना और यह क्यों महत्वपूर्ण है

LoRA, जो Low-Rank Adaptation का संक्षिप्त रूप है, पूरे मॉडल को संशोधित करने के बजाय थोड़ी संख्या में अतिरिक्त पैरामीटर ट्रेन करके बड़े न्यूरल नेटवर्क को फाइन-ट्यून करने की एक तकनीक है। मूल Stable Diffusion मॉडल में लगभग एक अरब पैरामीटर हैं। पूर्ण फाइन-ट्यूनिंग के लिए उन सभी को संशोधित करने की आवश्यकता होगी, जिसके लिए पर्याप्त GPU मेमोरी और विस्तारित ट्रेनिंग समय की आवश्यकता होती है।

LoRA मूल मॉडल वेट को फ्रीज करके और छोटे एडाप्टर मैट्रिक्स ट्रेन करके इस समस्या से बचता है जो मॉडल द्वारा जानकारी संसाधित करने के तरीके को संशोधित करते हैं। एक सामान्य LoRA फ़ाइल दस से दो सौ मेगाबाइट के बीच होती है, जबकि पूर्ण Stable Diffusion चेकपॉइंट का आकार दो से छह गीगाबाइट होता है।

व्यावहारिक प्रभाव महत्वपूर्ण हैं:

**मेमोरी दक्षता।** LoRA ट्रेनिंग के लिए पूर्ण फाइन-ट्यूनिंग की तुलना में बहुत कम GPU VRAM की आवश्यकता होती है। 24GB GPU आराम से SDXL मॉडल के लिए LoRA ट्रेन कर सकता है जिसके लिए अन्यथा पूर्ण फाइन-ट्यूनिंग के लिए 40GB या अधिक की आवश्यकता होगी।

**ट्रेनिंग गति।** क्योंकि आप कम पैरामीटर ट्रेन कर रहे हैं, प्रत्येक ट्रेनिंग epoch तेजी से पूरा होता है। जो पूर्ण फाइन-ट्यूनिंग के लिए बारह घंटे ले सकता है वह अक्सर LoRA के साथ नब्बे मिनट में पूरा हो सकता है।

**संयोजनशीलता।** inference समय पर कई LoRA को संयोजित किया जा सकता है। आप कलात्मक शैली के लिए एक LoRA और चरित्र स्थिरता के लिए दूसरा उपयोग कर सकते हैं, उन्हें पुनः ट्रेनिंग के बिना अलग-अलग शक्तियों पर मिला सकते हैं।

**स्टोरेज और वितरण।** छोटे फ़ाइल आकार LoRA को साझा करने और बनाए रखने के लिए व्यावहारिक बनाते हैं। आप स्टोरेज चिंताओं के बिना दर्जनों विशेष LoRA को हाथ में रख सकते हैं।

इन दक्षताओं से लागत में कमी वही है जो दस डॉलर से कम ट्रेनिंग को संभव बनाती है। आप आठ से चौबीस घंटों के बजाय एक से तीन घंटे के लिए महंगे हार्डवेयर किराए पर ले रहे हैं।

---

## ट्रेनिंग के लिए सही GPU का चयन

GPU चयन में तीन कारकों को संतुलित करना शामिल है: VRAM क्षमता, ट्रेनिंग गति, और किराया लागत। न्यूनतम व्यवहार्य विकल्प और इष्टतम विकल्प काफी भिन्न हैं।

### VRAM आवश्यकताएं

Stable Diffusion 1.5 LoRA ट्रेनिंग के लिए, 12GB VRAM व्यावहारिक न्यूनतम है। आप batch size और resolution कम करके 8GB के साथ काम कर सकते हैं, लेकिन ट्रेनिंग गुणवत्ता अक्सर प्रभावित होती है।

SDXL LoRA ट्रेनिंग के लिए, 16GB न्यूनतम है, जिसमें 24GB की दृढ़ता से अनुशंसा की जाती है। SDXL मॉडल बड़े और अधिक मांग वाले हैं। अपर्याप्त VRAM पर SDXL ट्रेनिंग का प्रयास लगातार मेमोरी स्वैपिंग का परिणाम होता है, जो प्रक्रिया को नाटकीय रूप से धीमा कर देता है और अक्सर ट्रेनिंग विफलताओं का कारण बनता है।

### गति और लागत ट्रेडऑफ

अधिक महंगे GPU तेजी से ट्रेन करते हैं, लेकिन प्रति-घंटा लागत वृद्धि हमेशा कुल प्रोजेक्ट लागत को आनुपातिक रूप से कम नहीं करती। एक सामान्य SD 1.5 LoRA ट्रेनिंग के लिए इस तुलना पर विचार करें:

| GPU         | VRAM | अनुमानित ट्रेनिंग समय | सामान्य प्रति घंटा दर | अनुमानित कुल लागत |
| ----------- | ---- | --------------------- | --------------------- | ----------------- |
| RTX 3090    | 24GB | 2.5 घंटे              | $0.50                 | $1.25             |
| RTX 4090    | 24GB | 1.5 घंटे              | $0.70                 | $1.05             |
| RTX A6000   | 48GB | 1.5 घंटे              | $0.80                 | $1.20             |
| A100 (40GB) | 40GB | 1.0 घंटे              | $1.50                 | $1.50             |

RTX 4090 आमतौर पर सबसे अच्छी लागत दक्षता प्रदान करता है। यह काफी कम प्रति घंटा दरों पर डेटासेंटर GPU जितनी तेजी से ट्रेन करता है। RTX 3090 तब भी व्यवहार्य रहता है जब 4090 उपलब्धता सीमित हो, केवल मामूली रूप से उच्च कुल लागत के साथ।

SDXL LoRA ट्रेनिंग के लिए, गणना थोड़ी बदल जाती है क्योंकि बड़ा मॉडल अतिरिक्त VRAM और मेमोरी बैंडविड्थ से अधिक लाभान्वित होता है। A100 जटिल SDXL प्रोजेक्ट्स के लिए अधिक प्रतिस्पर्धी हो जाता है जहां ट्रेनिंग अन्यथा कंज्यूमर हार्डवेयर पर चार या अधिक घंटे ले सकती है।

एंटरप्राइज क्लाउड विकल्पों और मार्केटप्लेस प्लेटफॉर्म सहित सभी प्रमुख प्रदाताओं में GPU किराया मूल्य निर्धारण के व्यापक विश्लेषण के लिए, हमारी [2026 के लिए संपूर्ण GPU किराया मूल्य निर्धारण तुलना](/hi/gpu-rental-pricing-comparison-2026/) देखें।

![AI मॉडल ट्रेनिंग के लिए आमतौर पर उपयोग किया जाने वाला ट्रिपल-फैन कूलिंग सिस्टम के साथ NVIDIA RTX 4090 ग्राफिक्स कार्ड](../_images/nvidia-4090.jpg)

---

## GPU किराया प्रदाता तुलना

LoRA ट्रेनिंग वर्कलोड के लिए तीन प्रदाता विचार करने योग्य हैं। प्रत्येक की अलग-अलग विशेषताएं हैं जो आपकी भुगतान प्राथमिकताओं, तकनीकी आराम स्तर और लागत संवेदनशीलता के आधार पर महत्वपूर्ण हैं।

### Vast.ai

Vast.ai एक पीयर-टू-पीयर मार्केटप्लेस संचालित करता है जहां व्यक्तिगत GPU मालिक अपने हार्डवेयर को किराए पर सूचीबद्ध करते हैं। यह मॉडल बाजार में सबसे कम कीमतें उत्पन्न करता है, RTX 4090 GPU अक्सर $0.35 से $0.60 प्रति घंटे पर उपलब्ध होते हैं।

ट्रेडऑफ में परिवर्तनशीलता शामिल है। प्रदाता विश्वसनीयता व्यक्तिगत होस्ट के आधार पर 97% से 99.9% तक होती है। मांग के आधार पर उपलब्धता में उतार-चढ़ाव होता है। आपको अपने डेटासेट अपलोड के लिए स्वीकार्य नेटवर्क गति वाला एक खोजने से पहले कई प्रदाताओं को आज़माना पड़ सकता है।

प्रदाता मेट्रिक्स का मूल्यांकन करने में सहज अनुभवी उपयोगकर्ताओं के लिए, Vast.ai सबसे कम संभव ट्रेनिंग लागत प्रदान करता है। प्रारंभिक सेटअप और प्रदाता मूल्यांकन के लिए अतिरिक्त तीस मिनट का बजट रखें।

### RunPod

RunPod शुद्ध मार्केटप्लेस और एंटरप्राइज क्लाउड प्रदाताओं के बीच खुद को स्थित करता है। प्लेटफॉर्म कम्युनिटी-सोर्स्ड GPU और अधिक सुसंगत प्रदर्शन के साथ समर्पित "Secure Cloud" इंस्टेंस दोनों प्रदान करता है।

मूल्य निर्धारण Vast.ai से थोड़ा अधिक है, आमतौर पर Secure Cloud टियर पर RTX 4090 एक्सेस के लिए $0.59 प्रति घंटा। प्लेटफॉर्म आसान सेटअप, सामान्य AI वर्कलोड के लिए पूर्व-कॉन्फ़िगर टेम्प्लेट, और अधिक अनुमानित उपलब्धता के साथ क्षतिपूर्ति करता है।

GPU किराए में नए उपयोगकर्ताओं या उन लोगों के लिए जो न्यूनतम लागत अनुकूलन पर सीधे इंटरफेस को महत्व देते हैं, RunPod एक उचित मध्य मार्ग का प्रतिनिधित्व करता है।

### GPUFlow

GPUFlow ब्लॉकचेन इंफ्रास्ट्रक्चर पर निर्मित एक पीयर-टू-पीयर मार्केटप्लेस संचालित करता है, भुगतान प्रसंस्करण के लिए स्मार्ट कॉन्ट्रैक्ट एस्क्रो का उपयोग करता है। प्लेटफॉर्म क्रिप्टोकरेंसी भुगतान स्वीकार करता है और किसी पहचान सत्यापन की आवश्यकता नहीं है।

मूल्य निर्धारण आमतौर पर Vast.ai और RunPod के बीच आता है, RTX 4090 एक्सेस $0.50 से $0.80 प्रति घंटे पर। विशिष्ट विशेषताएं भुगतान गोपनीयता, तत्काल सेटअप (आमतौर पर एक चलने वाले इंस्टेंस के लिए तीस सेकंड से कम), और प्रतिस्पर्धी मार्केटप्लेस से कम प्लेटफॉर्म शुल्क हैं।

उन उपयोगकर्ताओं के लिए जो क्रिप्टोकरेंसी भुगतान पसंद करते हैं, लेनदेन गोपनीयता को महत्व देते हैं, या पारंपरिक प्रदाताओं के साथ सामान्य खाता सत्यापन प्रक्रियाओं से बचना चाहते हैं, GPUFlow एक सुव्यवस्थित विकल्प प्रदान करता है।

### प्रदाता सारांश

| प्रदाता | RTX 4090 मूल्य सीमा       | सेटअप समय | भुगतान विकल्प           | इसके लिए सर्वश्रेष्ठ |
| ------- | ------------------------- | --------- | ----------------------- | -------------------- |
| Vast.ai | $0.35-0.60/घंटा           | 5-15 मिनट | क्रेडिट कार्ड           | अधिकतम लागत बचत      |
| RunPod  | $0.59/घंटा (Secure Cloud) | 2-5 मिनट  | क्रेडिट कार्ड, क्रिप्टो | उपयोग में आसानी      |
| GPUFlow | $0.50-0.80/घंटा           | 30 सेकंड  | केवल क्रिप्टो           | गोपनीयता, गति        |

## अपना ट्रेनिंग डेटासेट तैयार करना

डेटासेट गुणवत्ता किसी भी अन्य कारक से अधिक ट्रेनिंग परिणाम निर्धारित करती है। सावधानीपूर्वक क्यूरेट किया गया तीस इमेज का सेट लापरवाही से इकट्ठा किए गए दो सौ इमेज के संग्रह से बेहतर परिणाम देगा।

### इमेज चयन मानदंड

**स्थिरता।** सभी इमेज उस अवधारणा का प्रतिनिधित्व करनी चाहिए जो आप चाहते हैं कि मॉडल सीखे। यदि किसी विशिष्ट व्यक्ति के चेहरे पर ट्रेनिंग कर रहे हैं, तो प्रत्येक इमेज में वह चेहरा स्पष्ट रूप से दिखाई देना चाहिए। यदि किसी कलात्मक शैली पर ट्रेनिंग कर रहे हैं, तो प्रत्येक इमेज उस शैली का उदाहरण होनी चाहिए।

**स्थिरता के भीतर विविधता।** वैचारिक स्थिरता बनाए रखते हुए, तकनीकी पहलुओं में विविधता लाएं। विभिन्न कोण, प्रकाश स्थितियां, पृष्ठभूमि और संदर्भ शामिल करें। यह विविधता मॉडल को विशिष्ट रचनाओं पर ओवरफिट होने के बजाय सामान्यीकरण करना सिखाती है।

**तकनीकी गुणवत्ता।** तेज, अच्छी तरह से एक्सपोज्ड इमेज का उपयोग करें। मोशन ब्लर, नॉइज़, कंप्रेशन आर्टिफैक्ट्स, और खराब लाइटिंग सभी उसका हिस्सा बन जाते हैं जो मॉडल सीखता है। यदि आपकी ट्रेनिंग इमेज दानेदार हैं, तो आपकी जनरेट की गई इमेज भी दानेदार होने की प्रवृत्ति रखेंगी।

**रिज़ॉल्यूशन।** ट्रेनिंग इमेज SD 1.5 के लिए कम से कम 512x512 पिक्सेल और SDXL के लिए कम से कम 1024x1024 होनी चाहिए। उच्च रिज़ॉल्यूशन स्रोत इमेज ट्रेनिंग पाइपलाइन को गुणवत्ता हानि के बिना क्रॉप और रीसाइज़ करने की अनुमति देती हैं।

### डेटासेट आकार दिशानिर्देश

इष्टतम डेटासेट आकार अवधारणा जटिलता पर निर्भर करता है:

**सरल अवधारणाएं (एकल चेहरा, बुनियादी शैली):** 20-40 इमेज
**मध्यम अवधारणाएं (कई पोशाकों वाला चरित्र, सूक्ष्म शैली):** 40-80 इमेज
**जटिल अवधारणाएं (विस्तृत वातावरण, अत्यधिक परिवर्तनशील शैली):** 80-150 इमेज

अधिक इमेज के लिए अधिक ट्रेनिंग स्टेप्स की आवश्यकता होती है, जिससे समय और लागत बढ़ती है। अपने पहले प्रयासों के लिए इन सीमाओं के छोटे छोर से शुरू करें।

### अपनी इमेज को कैप्शन देना

प्रत्येक ट्रेनिंग इमेज को उसकी सामग्री का वर्णन करने वाले टेक्स्ट कैप्शन की आवश्यकता होती है। ये कैप्शन मॉडल को सिखाते हैं कि कौन सी टेक्स्ट अवधारणाओं को विज़ुअल पैटर्न के साथ जोड़ना है।

प्रभावी कैप्शन विशिष्ट और सुसंगत होते हैं:

**खराब कैप्शन:** "एक महिला"
**बेहतर कैप्शन:** "सारा मिलर की एक तस्वीर, छोटे भूरे बालों और हरी आंखों वाली एक महिला, नीला स्वेटर पहने हुए"

**खराब कैप्शन:** "फैंटसी आर्ट"
**बेहतर कैप्शन:** "ल्यूमिनसेंट फैंटसी शैली में एक डिजिटल पेंटिंग, एक अंधेरे जंगल में चमकते मशरूम को दर्शाती है, विस्तृत लाइनवर्क, जीवंत बैंगनी और नीली रंग पैलेट"

वह ट्रिगर शब्द या वाक्यांश जो आप inference के दौरान उपयोग करना चाहते हैं, प्रत्येक कैप्शन में दिखाई देना चाहिए। यदि आप "ल्यूमिनसेंट फैंटसी की शैली में" के साथ अपना LoRA इन्वोक करना चाहते हैं, तो वह सटीक वाक्यांश प्रत्येक ट्रेनिंग कैप्शन में दिखाई देना चाहिए।

छोटे डेटासेट के लिए कैप्शनिंग मैन्युअल रूप से की जा सकती है। बड़े संग्रहों के लिए, BLIP या WD14 Tagger जैसे टूल प्रारंभिक कैप्शन जनरेट कर सकते हैं जिन्हें आप फिर समीक्षा और परिष्कृत करते हैं।

![LoRA ट्रेनिंग के लिए ट्रेनिंग इमेज और उनकी संबंधित कैप्शन टेक्स्ट फाइलों को दिखाता संगठित फोल्डर संरचना](../_images/file-folder-organization.png)

### डायरेक्टरी संरचना

अपने ट्रेनिंग डेटा को एक विशिष्ट संरचना में व्यवस्थित करें जो ट्रेनिंग स्क्रिप्ट अपेक्षा करती हैं:

```
training_data/
├── 10_concept_name/
│   ├── image001.jpg
│   ├── image001.txt
│   ├── image002.jpg
│   ├── image002.txt
│   └── ...
```

फोल्डर नाम प्रीफिक्स (इस उदाहरण में "10") इंगित करता है कि उस फोल्डर में प्रत्येक इमेज को ट्रेनिंग के दौरान कितनी बार दोहराया जाना चाहिए। उच्च संख्याएं ट्रेनिंग प्रक्रिया में उन इमेज का वजन बढ़ाती हैं।

संख्या के बाद अंडरस्कोर-पृथक नाम डिफ़ॉल्ट ट्रिगर शब्द बन जाता है यदि आप कस्टम कैप्शन का उपयोग नहीं करना चुनते हैं।

---

## ट्रेनिंग वातावरण सेट करना

आपका डेटासेट तैयार होने और GPU किराया सुरक्षित होने के बाद, अगला कदम ट्रेनिंग वातावरण को कॉन्फ़िगर करना है। LoRA ट्रेनिंग के लिए मानक टूलचेन kohya_ss/sd-scripts है, जो समुदाय द्वारा बनाए रखा गया ट्रेनिंग स्क्रिप्ट का एक ओपन-सोर्स संग्रह है।

### प्रारंभिक वातावरण सेटअप

अपने किराए के GPU इंस्टेंस से कनेक्ट होने के बाद, आपको ट्रेनिंग रिपॉजिटरी क्लोन करनी होगी और डिपेंडेंसी इंस्टॉल करनी होंगी। निम्नलिखित कमांड बुनियादी वातावरण स्थापित करते हैं:

```bash
# ट्रेनिंग स्क्रिप्ट रिपॉजिटरी क्लोन करें
git clone https://github.com/kohya-ss/sd-scripts.git
cd sd-scripts

# वर्चुअल एनवायरनमेंट बनाएं और एक्टिवेट करें
python -m venv venv
source venv/bin/activate

# डिपेंडेंसी इंस्टॉल करें
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
pip install -r requirements.txt
pip install xformers
```

यह इंस्टॉलेशन नेटवर्क स्पीड के आधार पर आमतौर पर पांच से दस मिनट लेता है। xformers पैकेज वैकल्पिक है लेकिन अनुशंसित है, क्योंकि यह ट्रेनिंग के दौरान मेमोरी उपयोग को काफी कम करता है।

### बेस मॉडल डाउनलोड करना

LoRA ट्रेनिंग के लिए ट्रेन करने के लिए एक बेस Stable Diffusion मॉडल की आवश्यकता होती है। आपको इसे अपने इंस्टेंस पर डाउनलोड करना होगा:

```bash
# मॉडल डायरेक्टरी बनाएं
mkdir -p models/sd

# Stable Diffusion 1.5 डाउनलोड करें (लगभग 4GB)
wget -O models/sd/v1-5-pruned.safetensors \
  "https://huggingface.co/runwayml/stable-diffusion-v1-5/resolve/main/v1-5-pruned.safetensors"
```

SDXL ट्रेनिंग के लिए, SDXL बेस मॉडल को प्रतिस्थापित करें, जो लगभग 6.5GB है।

### अपना ट्रेनिंग डेटा अपलोड करना

अपने तैयार डेटासेट को GPU इंस्टेंस में ट्रांसफर करें। अधिकांश प्रदाता SCP या SFTP सपोर्ट करते हैं:

```bash
# अपनी लोकल मशीन से
scp -r ./training_data user@gpu-instance-ip:~/sd-scripts/
```

वैकल्पिक रूप से, यदि आपका डेटासेट क्लाउड स्टोरेज में संग्रहीत है, तो आप wget या rclone का उपयोग करके इसे सीधे इंस्टेंस पर डाउनलोड कर सकते हैं।

### GPUFlow-विशिष्ट सेटअप

यदि GPUFlow का उपयोग कर रहे हैं, तो प्लेटफॉर्म पूर्व-कॉन्फ़िगर वातावरण प्रदान करता है जो अधिकांश मैनुअल सेटअप को समाप्त करता है। वेब-आधारित टर्मिनल के माध्यम से कनेक्ट करने के बाद:

```bash
# GPUFlow इंस्टेंस में पूर्व-इंस्टॉल्ड ट्रेनिंग वातावरण शामिल है
cd /workspace/sd-scripts

# वेब इंटरफेस या SCP का उपयोग करके अपना डेटासेट अपलोड करें
# ट्रेनिंग स्क्रिप्ट पूर्व-कॉन्फ़िगर और उपयोग के लिए तैयार हैं
```

यह पूर्व-कॉन्फ़िगरेशन आमतौर पर स्क्रैच से बेयर इंस्टेंस सेट करने की तुलना में पंद्रह से बीस मिनट बचाता है। कभी-कभार ट्रेनिंग रन के लिए, यह समय बचत आपके कुल GPU किराए का एक सार्थक प्रतिशत प्रतिनिधित्व कर सकती है।

---

## ट्रेनिंग पैरामीटर कॉन्फ़िगर करना

ट्रेनिंग कॉन्फ़िगरेशन आउटपुट गुणवत्ता और ट्रेनिंग अवधि दोनों को काफी प्रभावित करता है। नीचे दिए गए पैरामीटर रूढ़िवादी शुरुआती बिंदुओं का प्रतिनिधित्व करते हैं जो अत्यधिक गणना के बिना विश्वसनीय परिणाम उत्पन्न करते हैं।

### आवश्यक पैरामीटर

`training_config.toml` नाम की एक कॉन्फ़िगरेशन फाइल बनाएं:

```toml
[model]
pretrained_model_name_or_path = "./models/sd/v1-5-pruned.safetensors"
v2 = false
v_parameterization = false

[dataset]
train_data_dir = "./training_data"
resolution = 512
batch_size = 2
enable_bucket = true
min_bucket_reso = 256
max_bucket_reso = 1024

[training]
output_dir = "./output"
output_name = "my_lora"
max_train_epochs = 10
learning_rate = 1e-4
unet_lr = 1e-4
text_encoder_lr = 5e-5
lr_scheduler = "cosine_with_restarts"
lr_warmup_steps = 100
network_dim = 32
network_alpha = 16
optimizer_type = "AdamW8bit"
mixed_precision = "fp16"
save_every_n_epochs = 2
save_model_as = "safetensors"
```

### पैरामीटर स्पष्टीकरण

**resolution:** इसे अपने लक्ष्य inference रिज़ॉल्यूशन से मिलाएं। SD 1.5 के लिए 512, SDXL के लिए 1024।

**batch_size:** उच्च मान तेजी से ट्रेन करते हैं लेकिन अधिक VRAM की आवश्यकता होती है। 2 से शुरू करें, यदि मेमोरी अनुमति दे तो 4 तक बढ़ाएं।

**max_train_epochs:** एक epoch का मतलब है कि मॉडल प्रत्येक ट्रेनिंग इमेज को एक बार देखता है। अधिकांश डेटासेट के लिए दस epochs एक उचित शुरुआती बिंदु है।

**learning_rate:** नियंत्रित करता है कि मॉडल कितनी आक्रामकता से अपडेट होता है। ऊपर के मान रूढ़िवादी हैं। यदि परिणाम कमजोर हैं, तो 2e-4 या 3e-4 तक बढ़ाने का प्रयास करें।

**network_dim और network_alpha:** ये LoRA क्षमता को नियंत्रित करते हैं। Dim 32 के साथ alpha 16 गुणवत्ता और फाइल आकार को संतुलित करता है। उच्च आयाम (64, 128) अधिक विवरण कैप्चर कर सकते हैं लेकिन बड़ी फाइलें उत्पन्न करते हैं और ओवरफिटिंग का जोखिम होता है।

**optimizer_type:** AdamW8bit न्यूनतम गुणवत्ता प्रभाव के साथ मेमोरी उपयोग को काफी कम करता है। SDXL ट्रेनिंग करने वाले 24GB कार्ड के लिए आवश्यक।

**mixed_precision:** FP16 ट्रेनिंग FP32 की तुलना में मेमोरी आवश्यकताओं को आधा कर देती है। अधिकांश उपयोग मामलों के लिए गुणवत्ता प्रभाव नगण्य है।

### अपने हार्डवेयर के लिए समायोजन

24GB VRAM वाले RTX 4090 के लिए:

- batch_size = 4 आमतौर पर SD 1.5 के लिए सुरक्षित है
- batch_size = 2 SDXL के लिए

24GB VRAM वाले RTX 3090 के लिए:

- batch_size = 2 SD 1.5 के लिए
- batch_size = 1 SDXL के लिए (gradient checkpointing सक्षम करें)

40GB VRAM वाले A100 के लिए:

- batch_size = 6-8 SD 1.5 के लिए
- batch_size = 4 SDXL के लिए

उच्च batch sizes कुल ट्रेनिंग समय को आनुपातिक रूप से कम करते हैं। batch size को दोगुना करने से आवश्यक optimization steps लगभग आधे हो जाते हैं।

![learning rate, batch size, और network dimensions के पैरामीटर के साथ LoRA ट्रेनिंग कॉन्फ़िगरेशन फाइल दिखाता कोड एडिटर](../_images/terminal-screenshot-code-editor.png)

---

## ट्रेनिंग रन निष्पादित करना

वातावरण कॉन्फ़िगर और पैरामीटर सेट होने के बाद, ट्रेनिंग शुरू करें:

```bash
accelerate launch --num_cpu_threads_per_process=4 train_network.py \
  --config_file="./training_config.toml" \
  --logging_dir="./logs"
```

### प्रगति की निगरानी

ट्रेनिंग आउटपुट loss values और प्रगति जानकारी प्रदर्शित करता है:

```
epoch 1/10, step 50/500, loss=0.0823
epoch 1/10, step 100/500, loss=0.0756
epoch 1/10, step 150/500, loss=0.0691
...
```

**क्या देखना है:**

Loss आमतौर पर पहले कुछ epochs में कम होना चाहिए, फिर स्थिर होना चाहिए। एक सामान्य ट्रेनिंग रन दिखा सकता है:

- Epoch 1: loss लगभग 0.08-0.10
- Epoch 5: loss लगभग 0.05-0.07
- Epoch 10: loss लगभग 0.04-0.06

यदि प्रारंभिक कमी के बाद loss बढ़ता है, तो मॉडल ओवरफिट हो सकता है। यदि loss शुरू से ही फ्लैट रहता है, तो learning rate बहुत कम हो सकती है।

### चेकपॉइंटिंग

कॉन्फ़िगरेशन हर दो epochs में checkpoints सेव करता है। ये इंटरमीडिएट सेव दो उद्देश्यों की सेवा करते हैं:

1. **रिकवरी।** यदि ट्रेनिंग क्रैश हो जाती है या आपको जल्दी समाप्त करने की आवश्यकता है, तो आप अंतिम checkpoint से फिर से शुरू कर सकते हैं।

2. **चयन।** विभिन्न epochs कभी-कभी विभिन्न विशेषताएं उत्पन्न करते हैं। Epoch 6 आपकी अवधारणा को अच्छी तरह से कैप्चर कर सकता है जबकि epoch 10 ओवरफिट हो जाता है। checkpoints होने से आप परीक्षण और चयन कर सकते हैं।

### अपेक्षित ट्रेनिंग समय

ऊपर दिए गए कॉन्फ़िगरेशन के साथ 50-इमेज SD 1.5 LoRA के लिए:

| GPU      | अनुमानित समय |
| -------- | ------------ |
| RTX 3090 | 90-120 मिनट  |
| RTX 4090 | 60-90 मिनट   |
| A100     | 45-60 मिनट   |

SDXL ट्रेनिंग के लिए इन अवधियों का लगभग 1.5x से 2x समय आवश्यक है।

## अपने LoRA को मान्य और परीक्षण करना

ट्रेनिंग पूरी होने पर आपकी आउटपुट डायरेक्टरी में एक .safetensors फाइल उत्पन्न होती है। प्रोजेक्ट को पूर्ण मानने से पहले इस फाइल का परीक्षण आवश्यक है।

### बुनियादी सत्यापन

LoRA फाइल को अपनी लोकल मशीन या Stable Diffusion WebUI चलाने वाली सिस्टम पर कॉपी करें:

```bash
# GPU इंस्टेंस से डाउनलोड करें
scp user@gpu-instance-ip:~/sd-scripts/output/my_lora.safetensors ./
```

Automatic1111 WebUI में, फाइल को `models/Lora` डायरेक्टरी में रखें। ComfyUI के लिए, `models/loras` डायरेक्टरी का उपयोग करें।

### परीक्षण पद्धति

इन कारकों में विविधता लाते हुए परीक्षण इमेज की एक श्रृंखला जनरेट करें:

**LoRA वेट:** 0.5, 0.7, 0.8, और 1.0 स्ट्रेंथ पर परीक्षण करें। कुछ LoRA पूर्ण स्ट्रेंथ से नीचे सबसे अच्छा काम करते हैं।

**प्रॉम्प्ट पोजिशनिंग:** प्रॉम्प्ट में अलग-अलग स्थानों पर अपना ट्रिगर शब्द शामिल करें। शुरुआत, मध्य और अंत की स्थिति सूक्ष्म रूप से भिन्न परिणाम उत्पन्न कर सकती है।

**नेगेटिव प्रॉम्प्ट:** नेगेटिव प्रॉम्प्ट में अपनी अवधारणा के साथ और बिना परीक्षण करें। कभी-कभी ट्रिगर को नेगेटिव में जोड़ना और कम वेट का उपयोग करना दिलचस्प उलटाव बनाता है।

**विभिन्न seed मान:** सुसंगत पैटर्न को यादृच्छिक भिन्नता से अलग करने के लिए प्रत्येक कॉन्फ़िगरेशन के लिए कम से कम पांच अलग-अलग seeds का उपयोग करें।

### गुणवत्ता मूल्यांकन

इन मानदंडों के विरुद्ध अपने परिणामों का मूल्यांकन करें:

**अवधारणा सटीकता:** क्या जनरेट किया गया आउटपुट आपकी ट्रेनिंग अवधारणा को प्रतिबिंबित करता है? यदि आपने एक चेहरे पर ट्रेनिंग की, तो क्या वह चेहरा पहचानने योग्य है?

**एकीकरण:** क्या LoRA अवधारणा अन्य प्रॉम्प्ट तत्वों के साथ स्वाभाविक रूप से एकीकृत होती है? क्या आप अपने प्रशिक्षित चरित्र को विभिन्न दृश्यों में रख सकते हैं?

**आर्टिफैक्ट्स:** लगातार दिखाई देने वाले दोहराए गए पैटर्न, अप्राकृतिक तत्वों, या विकृतियों की तलाश करें। ये ट्रेनिंग समस्याओं या ओवरफिटिंग का संकेत देते हैं।

**लचीलापन:** एज केस का परीक्षण करें। यदि आपने एक चरित्र को प्रशिक्षित किया, तो क्या उन्हें अलग-अलग उम्र में चित्रित किया जा सकता है? अलग-अलग कपड़ों में? विभिन्न क्रियाएं करते हुए?

यदि परिणाम असंतोषजनक हैं, तो सामान्य उपाय शामिल हैं:

- अधिक epochs के लिए ट्रेनिंग (अंडरफिटिंग)
- कम epochs के लिए ट्रेनिंग (ओवरफिटिंग)
- learning rate समायोजित करना
- कैप्शन गुणवत्ता में सुधार करना
- अधिक विविध ट्रेनिंग इमेज जोड़ना

![विभिन्न LoRA स्ट्रेंथ मानों पर Stable Diffusion आउटपुट दिखाने वाला तुलना ग्रिड जो AI-जनरेटेड इमेज में गुणवत्ता अंतर प्रदर्शित करता है](../_images/side-by-side-comparison.png)

---

## लागत अनुकूलन रणनीतियां

पांच-डॉलर ट्रेनिंग रन और बीस-डॉलर ट्रेनिंग रन के बीच का अंतर अक्सर प्रदाता चयन के बजाय वर्कफ़्लो दक्षता पर आता है।

### अपलोड-पूर्व डेटासेट तैयारी

GPU किराया शुरू करने से पहले अपनी लोकल मशीन पर सभी डेटासेट क्यूरेशन, क्रॉपिंग और कैप्शनिंग पूरी करें। फाइलों को मैन्युअल रूप से समीक्षा और नाम बदलने के लिए $0.70 प्रति घंटा भुगतान करना उस हार्डवेयर का एक महंगा उपयोग है।

किराया शुरू करने से पहले चेकलिस्ट:

- सभी इमेज उचित आस्पेक्ट रेशियो में क्रॉप की गई हैं
- सभी कैप्शन लिखे और समीक्षा किए गए हैं
- डेटासेट सही फोल्डर संरचना में व्यवस्थित है
- ट्रेनिंग कॉन्फ़िगरेशन फाइल तैयार है
- परीक्षण कमांड लिखे और पेस्ट करने के लिए तैयार हैं

### बैच ट्रेनिंग

यदि आपको कई LoRA की आवश्यकता है, तो उन्हें एक ही सेशन में ट्रेन करें। वातावरण सेटअप और मॉडल डाउनलोड की निश्चित लागत सभी ट्रेनिंग रन में विभाजित हो जाती है।

उदाहरण के लिए, तीन अलग-अलग LoRA ट्रेनिंग:

- तीन अलग सेशन: 3 × (20 मिनट सेटअप + 90 मिनट ट्रेनिंग) = 330 मिनट
- एक बैच सेशन: 20 मिनट सेटअप + (3 × 90 मिनट ट्रेनिंग) = 290 मिनट

चालीस मिनट की बचत लगभग 15% लागत में कमी का प्रतिनिधित्व करती है।

### चेकपॉइंट परीक्षण रणनीति

epoch 15 तक ट्रेनिंग करने और अच्छे परिणामों की उम्मीद करने के बजाय, विचार करें:

1. epoch 6 तक ट्रेन करें (पूर्ण ट्रेनिंग समय का लगभग 60%)
2. checkpoint का परीक्षण करें
3. यदि संतोषजनक है, तो रुकें और शेष GPU समय बचाएं
4. यदि अंडरफिटिंग है, तो checkpoint से ट्रेनिंग जारी रखें

यह दृष्टिकोण अक्सर अपेक्षा से पहले अच्छे परिणाम पकड़ता है, कुल लागत को कम करता है।

### तुरंत समाप्त करें

GPU बिलिंग आमतौर पर तब तक जारी रहती है जब तक आप स्पष्ट रूप से इंस्टेंस को रोकते नहीं हैं। अपनी आउटपुट फाइलें कॉपी करने के तुरंत बाद अपना सेशन बंद करें। $0.70 प्रति घंटे पर रात भर भूल गया चलता इंस्टेंस आपके प्रोजेक्ट की लागत में बारह डॉलर जोड़ता है।

### प्रदाता चयन समय

GPU उपलब्धता और मूल्य निर्धारण मांग के आधार पर उतार-चढ़ाव करते हैं। ऑफ-पीक घंटों में ट्रेनिंग (उदाहरण के लिए, US समय क्षेत्रों में सप्ताह के दिन की सुबह) अक्सर सप्ताहांत की शाम की तुलना में बेहतर मूल्य निर्धारण और GPU उपलब्धता प्रदान करती है।

---

## सामान्य समस्याएं और समाधान

### CUDA मेमोरी समाप्त

**लक्षण:** "CUDA out of memory" त्रुटि के साथ ट्रेनिंग क्रैश हो जाती है।

**समाधान:**

- कॉन्फ़िगरेशन में batch_size कम करें
- `gradient_checkpointing = true` जोड़कर gradient checkpointing सक्षम करें
- रिज़ॉल्यूशन कम करें (हालांकि यह आउटपुट गुणवत्ता को प्रभावित करता है)
- अधिक VRAM वाले GPU का उपयोग करें

### ट्रेनिंग Loss कम नहीं होता

**लक्षण:** Loss मान पूरी ट्रेनिंग में फ्लैट रहते हैं या यादृच्छिक रूप से उतार-चढ़ाव करते हैं।

**समाधान:**

- learning rate बढ़ाएं (2e-4 या 3e-4 आज़माएं)
- जांचें कि कैप्शन इमेज का सही वर्णन करते हैं
- सत्यापित करें कि इमेज सही ढंग से फॉर्मेट और पठनीय हैं
- सुनिश्चित करें कि बेस मॉडल पथ सही है

### LoRA का जनरेशन पर कोई प्रभाव नहीं

**लक्षण:** LoRA सक्षम या अक्षम होने पर जनरेट की गई इमेज समान दिखती हैं।

**समाधान:**

- सत्यापित करें कि LoRA फाइल आपके UI के लिए सही डायरेक्टरी में है
- जांचें कि ट्रिगर शब्द आपके ट्रेनिंग कैप्शन में उपयोग किए गए से मेल खाते हैं
- LoRA वेट/स्ट्रेंथ सेटिंग बढ़ाएं
- ट्रेनिंग से एक अलग checkpoint आज़माएं

### LoRA ओवरफिट और अनम्य

**लक्षण:** LoRA ट्रेनिंग इमेज को लगभग सटीक रूप से उत्पन्न करता है, लेकिन विभिन्न प्रॉम्प्ट के साथ विफल हो जाता है।

**समाधान:**

- कम epochs के लिए ट्रेन करें
- network_dim मान कम करें
- ट्रेनिंग डेटासेट में अधिक विविधता जोड़ें
- learning rate कम करें

### धीमी ट्रेनिंग गति

**लक्षण:** ट्रेनिंग अपेक्षित समय से बहुत धीमी गति से आगे बढ़ती है।

**समाधान:**

- सत्यापित करें कि GPU वास्तव में उपयोग किया जा रहा है (nvidia-smi को उच्च GPU उपयोग दिखाना चाहिए)
- सुनिश्चित करें कि xformers इंस्टॉल है
- जांचें कि mixed_precision सक्षम है
- यदि बहुत उच्च मान उपयोग कर रहे हैं तो network_dim कम करें

---

## अक्सर पूछे जाने वाले प्रश्न

### क्या मैं किराए के बजाय अपने GPU का उपयोग करके LoRA मॉडल ट्रेन कर सकता हूं?

हां, बशर्ते आपके पास कम से कम 12GB VRAM वाला NVIDIA GPU हो, जैसे RTX 3060 या बेहतर। हालांकि, बिजली की लागत, हार्डवेयर की टूट-फूट, और कंज्यूमर हार्डवेयर पर काफी लंबा ट्रेनिंग समय अक्सर कभी-कभार प्रोजेक्ट्स के लिए किराए को अधिक किफायती विकल्प बनाता है। $0.70 प्रति घंटे पर दो घंटे का ट्रेनिंग रन उस बिजली से कम खर्च करता है जो अधिकांश होम सेटअप धीमे हार्डवेयर पर आवश्यक चार से छह घंटे के लिए पूर्ण लोड पर चलने में खपत करते हैं।

### एक सामान्य LoRA ट्रेनिंग सेशन में कितना समय लगता है?

RTX 4090 या RTX 3090 का उपयोग करते समय अधिकांश LoRA ट्रेनिंग सेशन एक से तीन घंटे के भीतर पूरे हो जाते हैं। सटीक अवधि आपके डेटासेट के आकार, ट्रेनिंग epochs की संख्या और आपके batch size कॉन्फ़िगरेशन पर निर्भर करती है। समकक्ष ट्रेनिंग रन के लिए SDXL मॉडल को SD 1.5 की तुलना में लगभग 50-100% अधिक समय की आवश्यकता होती है।

### LoRA ट्रेनिंग के लिए न्यूनतम कितनी इमेज आवश्यक हैं?

आप पंद्रह से बीस इमेज के साथ भी उचित परिणाम प्राप्त कर सकते हैं। हालांकि, तीस से सौ अच्छी तरह से कैप्शन की गई इमेज वाले डेटासेट आमतौर पर बेहतर गुणवत्ता देते हैं। इमेज की गुणवत्ता और कैप्शन की सटीकता कच्ची मात्रा से अधिक महत्वपूर्ण है। तीस इमेज का एक अच्छी तरह से क्यूरेट किया गया सेट आमतौर पर जल्दबाजी में इकट्ठे किए गए सौ के संग्रह से बेहतर प्रदर्शन करता है।

### LoRA ट्रेनिंग के लिए कौन सा GPU किराया प्रदाता सबसे अच्छा मूल्य प्रदान करता है?

Vast.ai आमतौर पर RTX 4090 GPU के लिए सबसे कम प्रति घंटा दरें प्रदान करता है, अक्सर $0.35 से $0.50 प्रति घंटा। GPUFlow क्रिप्टोकरेंसी भुगतान विकल्पों और बिना पहचान सत्यापन आवश्यकताओं के साथ प्रतिस्पर्धी मूल्य निर्धारण प्रदान करता है। RunPod GPU किराए में नए उपयोगकर्ताओं के लिए सबसे सरल इंटरफ़ेस प्रदान करता है। सभी प्रदाताओं और वर्तमान मूल्य निर्धारण की विस्तृत तुलना के लिए, हमारी [व्यापक GPU किराया मूल्य निर्धारण तुलना](/hi/gpu-rental-pricing-comparison-2026/) देखें।

### क्या एक ही सेशन में कई LoRA मॉडल ट्रेन करना अधिक लागत-प्रभावी है?

हां। एक विस्तारित सेशन में कई LoRA को बैच ट्रेनिंग करने से बार-बार सेटअप समय समाप्त हो जाता है और निष्क्रिय GPU शुल्क कम हो जाते हैं। चार घंटे के सेशन में तीन से पांच LoRA मॉडल ट्रेन करने की लागत आमतौर पर अलग-अलग किराए में उन्हें व्यक्तिगत रूप से ट्रेन करने में खर्च होने वाली राशि की आधी से भी कम होती है।

### क्या मैं प्रशिक्षित LoRA का व्यावसायिक उपयोग कर सकता हूं?

यह आपके बेस मॉडल के लाइसेंस पर निर्भर करता है। Stable Diffusion 1.5 CreativeML Open RAIL-M लाइसेंस का उपयोग करता है, जो कुछ प्रतिबंधों के साथ व्यावसायिक उपयोग की अनुमति देता है। SDXL में समान अनुमेय लाइसेंसिंग है। आपका LoRA अपने बेस मॉडल से प्रतिबंध विरासत में लेता है। ट्रेनिंग इमेज में लाइसेंसिंग आवश्यकताएं भी हो सकती हैं—सुनिश्चित करें कि आपके पास ट्रेनिंग के लिए उपयोग की जाने वाली किसी भी इमेज के लिए उचित अधिकार हैं।

---

## निष्कर्ष

कस्टम LoRA मॉडल ट्रेनिंग उल्लेखनीय रूप से सुलभ हो गई है। कम्प्यूटेशनल बाधाएं जिनके लिए एक बार महत्वपूर्ण हार्डवेयर निवेश की आवश्यकता थी, अब GPU किराया शुल्क में कुछ डॉलर के बराबर हैं। इस गाइड में वर्णित तकनीकें, एक अच्छी तरह से तैयार डेटासेट पर लागू होने पर, पहले प्रयास में लगातार उपयोग योग्य परिणाम उत्पन्न करती हैं।

महत्वपूर्ण सफलता कारक अधिक महंगे ट्रेनिंग दृष्टिकोणों से अपरिवर्तित रहते हैं: गुणवत्ता ट्रेनिंग डेटा, उचित पैरामीटर चयन, और परिणामों का सावधानीपूर्वक सत्यापन। कोई भी कम्प्यूटेशनल पावर खराब स्रोत इमेज या गलत तरीके से कॉन्फ़िगर ट्रेनिंग रन की भरपाई नहीं करती।

बीस से तीस इमेज के एक मामूली डेटासेट से शुरू करें। रूढ़िवादी सेटिंग्स पर ट्रेन करें। बड़े प्रोजेक्ट्स में विस्तार करने से पहले अपने परिणामों का अच्छी तरह से परीक्षण करें। प्रति-प्रयास लागत इतनी कम है कि पुनरावृत्ति व्यावहारिक है—अपने पहले कुछ ट्रेनिंग रन को उत्पादन आउटपुट के बजाय सीखने के अनुभव के रूप में मानें।

उन लोगों के लिए जो सभी प्रदाता प्रकारों और मूल्य बिंदुओं में GPU किराया विकल्पों की तुलना कर रहे हैं, हमारी [GPU किराया मूल्य निर्धारण तुलना](/hi/gpu-rental-pricing-comparison-2026/) कंज्यूमर GPU, डेटासेंटर हार्डवेयर और एंटरप्राइज क्लाउड विकल्पों के लिए वर्तमान दरें प्रदान करती है।

---

_यह गाइड 12 फरवरी, 2026 को अंतिम बार अपडेट की गई थी। GPU किराया मूल्य निर्धारण और ट्रेनिंग टूल कॉन्फ़िगरेशन बार-बार बदलते हैं। ट्रेनिंग प्रोजेक्ट के लिए प्रतिबद्ध होने से पहले सीधे प्रदाताओं के साथ वर्तमान मूल्य निर्धारण सत्यापित करें।_
